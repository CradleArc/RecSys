{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "from functools import partial\n",
    "import os\n",
    "import time\n",
    "# 导入Paddle库\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import inference\n",
    "\n",
    "# 导入PaddleNLP相关的库\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset, MapDataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "# 忽略所有警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:19:57.033649100Z",
     "start_time": "2024-06-02T03:19:57.023291200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 数据读取逻辑\n",
    "def read_simcse_text(data_path):\n",
    "    \"\"\"Reads data.\"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            data = line.rstrip()\n",
    "            # 这里的text_a和text_b是一样的\n",
    "            yield {'text_a': data, 'text_b': data}\n",
    "\n",
    "\n",
    "# 数据集路径\n",
    "train_set_file = './data/train_demo.csv'\n",
    "train_ds = load_dataset(read_simcse_text, data_path=train_set_file, lazy=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:20:31.323357Z",
     "start_time": "2024-06-02T03:20:31.303325Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 在训练神经网络之前，我们需要构建小批量的数据，所以需要借助Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 明文数据 -> ID 序列训练数据\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        # 分布式批采样器加载数据的一个子集。\n",
    "        # 每个进程可以传递给DataLoader一个DistributedBatchSampler的实例，每个进程加载原始数据的一个子集。\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        # 批采样器的基础实现，\n",
    "        # 用于 paddle.io.DataLoader 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    # 组装mini-batch\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "\n",
    "def convert_example(example, tokenizer, max_seq_length=512, do_evalute=False):\n",
    "    result = []\n",
    "\n",
    "    for key, text in example.items():\n",
    "        if 'label' in key:\n",
    "            # do_evaluate\n",
    "            result += [example['label']]\n",
    "        else:\n",
    "            # do_train\n",
    "            encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "            input_ids = encoded_inputs[\"input_ids\"]\n",
    "            token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "            result += [input_ids, token_type_ids]\n",
    "\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:20:37.986080800Z",
     "start_time": "2024-06-02T03:20:37.985569200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-02 11:20:43,923] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\ernie_3.0_medium_zh_vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-02 11:20:43,948] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-02 11:20:43,948] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\special_tokens_map.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 语义索引的维度最大为64，可以根据自己的情况调节长度\n",
    "max_seq_length = 64\n",
    "# 根据经验 batch_size越大效果越好\n",
    "batch_size = 32\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-3.0-medium-zh')\n",
    "# 给convert_example赋予默认的值，如tokenizer，max_seq_length\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length)\n",
    "# [pad]对齐的函数\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # query_input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # query_segment\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # title_input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # tilte_segment\n",
    "): [data for data in fn(samples)]\n",
    "\n",
    "# 构建训练的Dataloader\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:20:43.993394300Z",
     "start_time": "2024-06-02T03:20:43.923159600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 模型构建\n",
    "\n",
    "接下来搭建SimCSE模型，主要部分是用query和title分别得到embedding向量，然后计算余弦相似度。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fa84f7db963c4efd82b971f3ef477c070e5300acee3e4e788b4a6c56dd31c003)\n",
    "\n",
    "\n",
    "上图是SimCSE的原理图，SimCSE主要是通过dropout来把同一个句子变成正样本（做两次前向，但是dropout有随机因素，所以产生的向量不一样，但是本质上还是表示的是同一句话），把一个batch里面其他的句子变成负样本的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SimCSE(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 pretrained_model,\n",
    "                 dropout=None,\n",
    "                 margin=0.0,\n",
    "                 scale=20,\n",
    "                 output_emb_size=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptm = pretrained_model\n",
    "        # 显式的加一个dropout来控制\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "\n",
    "        # if output_emb_size is greater than 0, then add Linear layer to reduce embedding_size,\n",
    "        # 考虑到性能和效率，我们推荐把output_emb_size设置成256\n",
    "        # 向量越大，语义信息越丰富，但消耗资源越多\n",
    "        self.output_emb_size = output_emb_size\n",
    "        if output_emb_size > 0:\n",
    "            weight_attr = paddle.ParamAttr(\n",
    "                initializer=nn.initializer.TruncatedNormal(std=0.02))\n",
    "            self.emb_reduce_linear = paddle.nn.Linear(\n",
    "                768, output_emb_size, weight_attr=weight_attr)\n",
    "\n",
    "        self.margin = margin\n",
    "        # 为了使余弦相似度更容易收敛，我们选择把计算出来的余弦相似度扩大scale倍，一般设置成20左右\n",
    "        self.sacle = scale\n",
    "\n",
    "    # 加入jit注释能够把该提取向量的函数导出成静态图\n",
    "    # 对应input_id,token_type_id两个\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),\n",
    "                                      paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None,\n",
    "                             with_pooler=True):\n",
    "\n",
    "        # Note: cls_embedding is poolerd embedding with act tanh\n",
    "        sequence_output, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                                  position_ids, attention_mask)\n",
    "\n",
    "        if with_pooler == False:\n",
    "            cls_embedding = sequence_output[:, 0, :]\n",
    "\n",
    "        if self.output_emb_size > 0:\n",
    "            cls_embedding = self.emb_reduce_linear(cls_embedding)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/functional/normalize_cn.html\n",
    "        cls_embedding = F.normalize(cls_embedding, p=2, axis=-1)\n",
    "        return cls_embedding\n",
    "\n",
    "    def forward(self,\n",
    "                query_input_ids,\n",
    "                title_input_ids,\n",
    "                query_token_type_ids=None,\n",
    "                query_position_ids=None,\n",
    "                query_attention_mask=None,\n",
    "                title_token_type_ids=None,\n",
    "                title_position_ids=None,\n",
    "                title_attention_mask=None):\n",
    "\n",
    "        # 第 1 次编码: 文本经过无监督语义索引模型编码后的语义向量\n",
    "        # [N, 768]\n",
    "        query_cls_embedding = self.get_pooled_embedding(\n",
    "            query_input_ids, query_token_type_ids, query_position_ids,\n",
    "            query_attention_mask)\n",
    "\n",
    "        # 第 2 次编码: 文本经过无监督语义索引模型编码后的语义向量\n",
    "        # [N, 768]\n",
    "        title_cls_embedding = self.get_pooled_embedding(\n",
    "            title_input_ids, title_token_type_ids, title_position_ids,\n",
    "            title_attention_mask)\n",
    "\n",
    "        # 相似度矩阵: [N, N]\n",
    "        cosine_sim = paddle.matmul(\n",
    "            query_cls_embedding, title_cls_embedding, transpose_y=True)\n",
    "\n",
    "        # substract margin from all positive samples cosine_sim()\n",
    "        # 填充self.margin值，比如margin为0.2，query_cls_embedding.shape[0]=2\n",
    "        # margin_diag: [0.2,0.2]\n",
    "        margin_diag = paddle.full(\n",
    "            shape=[query_cls_embedding.shape[0]],\n",
    "            fill_value=self.margin,\n",
    "            dtype=paddle.get_default_dtype())\n",
    "        # input paddle.diag(margin_diag): [[0.2,0],[0,0.2]]\n",
    "        # input cosine_sim : [[1.0,0.6],[0.6,1.0]]\n",
    "        # output cosine_sim: [[0.8,0.6],[0.6,0.8]]\n",
    "        cosine_sim = cosine_sim - paddle.diag(margin_diag)\n",
    "\n",
    "        # scale cosine to ease training converge\n",
    "        cosine_sim *= self.sacle\n",
    "\n",
    "        # 转化成多分类任务: 对角线元素是正例，其余元素为负例\n",
    "        # labels : [0,1,2,3]\n",
    "        labels = paddle.arange(0, query_cls_embedding.shape[0], dtype='int64')\n",
    "        # labels : [[0],[1],[2],[3]]\n",
    "        labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "\n",
    "        # 交叉熵损失函数\n",
    "        loss = F.cross_entropy(input=cosine_sim, label=labels)\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:20:47.080965600Z",
     "start_time": "2024-06-02T03:20:47.079813Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 训练配置：关键参数\n",
    "scale = 20  # 推荐值: 10 ~ 30\n",
    "margin = 0.1  # 推荐值: 0.0 ~ 0.2\n",
    "# SimCSE的dropout的参数，也可以使用预训练语言模型默认的dropout参数\n",
    "dropout = 0.2\n",
    "# 向量映射的维度，默认的输出是768维，推荐通过线性层映射成256维\n",
    "output_emb_size = 256\n",
    "# 训练的epoch数目\n",
    "epochs = 1\n",
    "weight_decay = 0.0\n",
    "# 学习率\n",
    "learning_rate = 5E-5\n",
    "warmup_proportion = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:20:50.144977500Z",
     "start_time": "2024-06-02T03:20:50.144977500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 加载预训练模型\n",
    "1. 加载预训练模型 ERNIE 3.0-Medium 进行热启\n",
    "2. 定义优化器 AdamOptimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-02 11:20:55,833] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-02 11:20:55,833] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-02 11:20:56,193] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-06-02 11:21:02,933] [ WARNING]\u001B[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieModel: ['ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.self_attn.v_proj.weight']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[33m[2024-06-02 11:21:02,933] [ WARNING]\u001B[0m - Some weights of ErnieModel were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['ernie.pooler.dense.weight', 'ernie.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ernie-3.0-medium-zh\n"
     ]
    }
   ],
   "source": [
    "# 设置 ERNIE-3.0-Medium-zh 预训练模型\n",
    "model_name_or_path = 'ernie-3.0-medium-zh'\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    hidden_dropout_prob=dropout,\n",
    "    attention_probs_dropout_prob=dropout)\n",
    "print(\"loading model from {}\".format(model_name_or_path))\n",
    "\n",
    "# 实例化SimCSE，SimCSE使用的Encoder是ERNIE-3.0-Medium-zh\n",
    "model = SimCSE(\n",
    "    pretrained_model,\n",
    "    margin=margin,\n",
    "    scale=scale,\n",
    "    output_emb_size=output_emb_size)\n",
    "# 训练的总步数\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "# warmpup操作，学习率先上升后下降\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                     warmup_proportion)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "# 设置优化器\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:21:02.969862900Z",
     "start_time": "2024-06-02T03:20:55.823610600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 模型训练\n",
    "\n",
    "上面的训练配置完毕以后，下面就可以开始训练了。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_dir = 'checkpoint'\n",
    "save_steps = 100\n",
    "time_start = time.time()\n",
    "global_step = 0\n",
    "tic_train = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        query_input_ids, query_token_type_ids, title_input_ids, title_token_type_ids = batch\n",
    "        # 其中query和title为同一条数据\n",
    "        loss = model(\n",
    "            query_input_ids=query_input_ids,\n",
    "            title_input_ids=title_input_ids,\n",
    "            query_token_type_ids=query_token_type_ids,\n",
    "            title_token_type_ids=title_token_type_ids)\n",
    "        # 每隔10个step进行打印日志\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                  % (global_step, epoch, step, loss,\n",
    "                     10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        # 反向\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "        # 每隔save_steps保存模型\n",
    "        if global_step % save_steps == 0:\n",
    "            save_path = os.path.join(save_dir, \"model_%d\" % (global_step))\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "            paddle.save(model.state_dict(), save_param_path)\n",
    "            tokenizer.save_pretrained(save_path)\n",
    "time_end = time.time()\n",
    "print('totally cost {} seconds'.format(time_end - time_start))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 模型预测\n",
    "\n",
    "由于本项目使用的demo数据，在预测部分为了保证效果，我们使用已经用全量数据训练好的模型，首先下载训练好的SimCSE模型，然后进行解压"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 256]\n",
      "[[-2.38936171e-02 -1.86179597e-02 -3.87326293e-02 -2.14510243e-02\n",
      "   5.80730699e-02 -7.30442628e-02  4.47707027e-02 -4.79865447e-03\n",
      "  -1.11777507e-01  3.06986496e-02 -7.58780241e-02 -1.39245540e-02\n",
      "  -3.18336859e-02  7.34863579e-02 -6.20127991e-02 -7.75121376e-02\n",
      "  -2.94753723e-02 -1.10602945e-01  1.43525824e-02  7.38698058e-03\n",
      "  -6.20281848e-04 -1.13605276e-01  5.09278849e-03  1.68028884e-02\n",
      "  -9.10069644e-02 -4.97759227e-03  9.68626812e-02 -4.01212536e-02\n",
      "  -4.31677513e-02 -6.29915670e-02 -2.77599022e-02 -1.28067151e-01\n",
      "   4.59447299e-04  1.12159485e-02 -2.34453306e-02 -1.29382834e-02\n",
      "  -9.12685394e-02  8.15406442e-02 -7.75527675e-03  3.35520543e-02\n",
      "  -7.50929788e-02 -6.48786947e-02  8.32832009e-02 -3.95188704e-02\n",
      "   1.33434922e-01 -7.62892142e-02  2.10594863e-01  9.67187062e-02\n",
      "  -4.11144681e-02  5.90532506e-03  2.87344866e-02 -1.25124678e-01\n",
      "  -9.30405185e-02 -1.03214726e-01  1.13968330e-03 -1.43238613e-02\n",
      "   9.50518623e-02 -1.65595077e-02 -4.30812314e-02  5.52676395e-02\n",
      "  -8.95094573e-02 -4.99802046e-02  2.48110220e-02 -1.93514246e-02\n",
      "   4.94862050e-02 -1.09978030e-02  3.30754779e-02 -8.02364871e-02\n",
      "  -7.09240213e-02  1.38881326e-01  1.55964484e-02  7.00399280e-02\n",
      "   4.87305410e-02 -3.24490219e-02 -6.10601828e-02 -9.60236508e-03\n",
      "  -7.82980770e-03 -1.70542430e-02 -3.72621194e-02  1.37725875e-01\n",
      "   1.55777242e-02 -7.80158152e-04 -4.65260260e-02 -7.25548267e-02\n",
      "   4.32729125e-02 -1.60146758e-01 -1.33182392e-01  9.39990208e-02\n",
      "  -5.65836951e-02  2.47459672e-02 -1.41402697e-02  3.96334231e-02\n",
      "   1.86874848e-02 -6.52665598e-03 -1.52942557e-02 -2.80678812e-02\n",
      "  -1.44324386e-02  9.96803418e-02  1.14819976e-02  2.26326417e-02\n",
      "  -1.88915452e-04 -3.69913802e-02 -5.13089262e-03  4.94119376e-02\n",
      "  -1.81786641e-02 -5.45423068e-02  2.44810227e-02  2.83814147e-02\n",
      "  -6.98113218e-02  9.37126502e-02 -2.98217200e-02 -3.92348915e-02\n",
      "   8.00552145e-02  3.25043350e-02 -2.96206418e-02 -5.61116748e-02\n",
      "  -4.70948704e-02 -8.08036774e-02 -7.62376860e-02  3.50234993e-02\n",
      "  -4.82863486e-02  5.54802194e-02 -1.09671557e-03  5.13044046e-03\n",
      "  -2.49400754e-02 -2.22539715e-02 -5.44783077e-04  4.51335907e-02\n",
      "   7.01561439e-05 -4.05995324e-02 -4.29379493e-02  3.79059166e-02\n",
      "   6.30532112e-03  6.31587952e-02  4.98235738e-03 -5.83176464e-02\n",
      "  -6.86376775e-03 -2.41296608e-02  4.68463153e-02 -3.49179246e-02\n",
      "   5.22721931e-02  1.13000028e-01 -3.63280550e-02 -5.63905351e-02\n",
      "   2.48677395e-02 -6.62251748e-03  1.03345588e-01 -9.29605775e-03\n",
      "   1.05893448e-01  6.61475062e-02 -2.14430355e-02 -3.44023295e-02\n",
      "   6.00234903e-02 -7.71017000e-02 -2.96891835e-02  3.57352346e-02\n",
      "  -2.43359208e-02  2.02705828e-03 -1.04504988e-01  7.09457994e-02\n",
      "  -5.85845113e-02  1.24924876e-01  7.78270066e-02 -1.95585545e-02\n",
      "   3.71500850e-02  5.04037067e-02  2.42853910e-02 -1.63062885e-02\n",
      "   7.55493790e-02 -8.22982751e-03  1.67472418e-02  4.17400114e-02\n",
      "   1.35832326e-02  1.05556801e-01 -4.44971807e-02  4.06498909e-02\n",
      "   1.18971400e-01  6.96983784e-02  4.82908711e-02 -8.89302865e-02\n",
      "  -8.10411107e-03 -2.27572094e-03 -4.19332944e-02 -3.53009962e-02\n",
      "   3.26378904e-02 -5.29955067e-02 -7.61810644e-03 -6.74278140e-02\n",
      "   3.21941376e-02  1.14661768e-01  2.74233967e-02  9.31852534e-02\n",
      "   1.07308896e-03  1.37721360e-01 -6.28966093e-02  3.04301027e-02\n",
      "  -1.84148774e-01 -8.67449343e-02  2.34652534e-02 -3.60179953e-02\n",
      "  -1.00319915e-01  4.44446802e-02 -7.72560388e-02  2.41001565e-02\n",
      "   7.44484439e-02  7.28243515e-02 -7.59818079e-03 -2.68514808e-02\n",
      "   1.23978123e-01  1.05049245e-01  1.17334826e-02 -6.96398467e-02\n",
      "  -4.13490906e-02  1.55874878e-01 -3.61632966e-02  4.39834818e-02\n",
      "  -6.35272940e-04 -9.51310843e-02 -1.75053068e-02  2.32684333e-02\n",
      "   3.60063538e-02  3.92234214e-02  1.78328101e-02 -2.34217923e-02\n",
      "  -1.78714380e-01 -8.96904916e-02 -3.32743116e-02  1.57977901e-02\n",
      "  -1.12955486e-02  1.83391999e-02  6.13671020e-02 -2.65253820e-02\n",
      "   4.08442505e-02  1.39107474e-03 -3.09836436e-02 -4.01387326e-02\n",
      "   3.94170545e-02  1.01407589e-02 -2.44590989e-03  2.67459024e-02\n",
      "   4.04687561e-02  9.23904777e-02 -6.14426807e-02 -6.31493405e-02\n",
      "   7.95214027e-02  6.45805523e-02 -3.13493200e-02  4.57527339e-02\n",
      "   7.49894157e-02  5.74484318e-02 -2.30828952e-02  4.22420464e-02\n",
      "   9.47391465e-02  9.97768790e-02  1.16430512e-02 -3.26821208e-02]\n",
      " [ 5.98876476e-02 -4.67539625e-03 -1.10207640e-01  3.38299274e-02\n",
      "   2.43929010e-02 -1.01046577e-01  4.29728534e-03  4.00339998e-02\n",
      "  -9.19079259e-02 -5.83520830e-02 -2.29058228e-02  7.81192109e-02\n",
      "  -4.08819970e-03  8.01766813e-02  5.24296761e-02 -1.00533860e-02\n",
      "   7.00081885e-02 -1.07360668e-01 -4.67482302e-03  1.15130663e-01\n",
      "  -1.76248346e-02 -5.94091564e-02  1.74166691e-02  2.30180882e-02\n",
      "   1.12048514e-01 -8.61317888e-02  5.68966791e-02 -3.57455984e-02\n",
      "   5.07172756e-03 -8.90962183e-02  7.01211914e-02  4.55992743e-02\n",
      "  -5.80560789e-03 -5.23530059e-02  1.51730068e-02  1.36996210e-01\n",
      "  -1.34410992e-01  3.30460956e-03  1.79281435e-03 -9.53789055e-02\n",
      "  -1.22772558e-02 -4.63729016e-02  6.99983537e-03 -3.32532898e-02\n",
      "   4.25921082e-02 -9.81957763e-02  1.21257454e-01  1.42998964e-01\n",
      "   3.50143574e-02 -9.85023007e-03  4.18281667e-02  5.82434162e-02\n",
      "   5.52991815e-02 -7.03922138e-02 -9.57520753e-02  9.46803391e-03\n",
      "   1.16223864e-01  2.80151851e-02 -3.30251902e-02 -5.84641211e-02\n",
      "  -3.38980965e-02 -6.48537055e-02  2.15261150e-02 -1.16891429e-01\n",
      "   6.29716218e-02  1.04986660e-01  3.03404778e-02  4.87276763e-02\n",
      "   1.46824587e-02  7.04762817e-04 -1.04485499e-02  1.71457008e-02\n",
      "   5.38535556e-03  6.86078891e-02 -4.83981567e-03 -8.79398137e-02\n",
      "   1.05693221e-01 -2.24042777e-02 -5.23625948e-02  1.24127403e-01\n",
      "   4.07421179e-02  6.81212768e-02 -3.91257815e-02  3.89558002e-02\n",
      "   2.37337258e-02 -3.07243653e-02 -1.22316152e-01  2.47302298e-02\n",
      "  -7.98637792e-02  6.67086476e-03  1.22887287e-02  9.22031999e-02\n",
      "   6.00558855e-02 -5.92697635e-02  1.22830197e-02 -2.00812370e-02\n",
      "  -2.19404344e-02  3.72038037e-02 -5.07596470e-02  5.85647821e-02\n",
      "   4.26812097e-02  2.86342651e-02 -9.98381674e-02  1.07276268e-01\n",
      "  -1.93709098e-02  1.80898439e-02 -2.07656417e-02  1.08140670e-01\n",
      "   2.56591639e-03  1.18653879e-01  3.11301500e-02  2.12134197e-02\n",
      "  -5.46023156e-03 -1.09993279e-01  4.14523147e-02 -7.17517138e-02\n",
      "  -1.03567831e-01 -6.39848635e-02 -8.01977934e-04 -1.85797568e-02\n",
      "  -1.14910677e-02  4.10608761e-02  9.33007058e-03 -6.32518297e-03\n",
      "   3.46878283e-02 -6.61663786e-02 -3.84401553e-03  8.73872917e-03\n",
      "   8.80816579e-02  7.76215568e-02 -2.91920751e-02  8.15580785e-02\n",
      "   3.55008505e-02  3.10492925e-02 -4.45909845e-03  8.02676082e-02\n",
      "  -1.24499546e-02  1.06032798e-02  6.93551600e-02 -5.33105396e-02\n",
      "  -2.35140324e-02  1.33174025e-02 -7.67698558e-03  3.32195731e-03\n",
      "   3.02499980e-02 -3.32984366e-02  8.44772682e-02  2.32913364e-02\n",
      "   7.94830695e-02 -6.08169474e-02 -3.99631970e-02  1.75625887e-02\n",
      "   1.37093052e-01 -2.14149244e-02  6.23604804e-02 -4.33418527e-02\n",
      "   1.25400469e-01 -2.90089864e-02 -3.52325626e-02  7.52617642e-02\n",
      "   1.18724415e-02  8.23247209e-02 -1.51907820e-02  5.82811004e-03\n",
      "  -2.88471989e-02  2.04949453e-02 -1.49239048e-01 -3.95601355e-02\n",
      "   1.67078860e-02 -4.44729067e-03 -2.13512834e-02  1.34153469e-02\n",
      "  -4.63214256e-02 -7.49955699e-03 -7.52882436e-02 -1.31220132e-01\n",
      "   1.65015489e-01 -9.30287763e-02  7.05149164e-03 -4.97146845e-02\n",
      "   3.96973034e-03  1.44314095e-02  8.90425816e-02 -4.38117981e-02\n",
      "  -6.85445517e-02 -1.90478545e-02 -6.36816025e-02 -4.07023691e-02\n",
      "   6.31273091e-02  6.78196102e-02  1.84689499e-02  2.43970584e-02\n",
      "   2.67180204e-02  4.51094881e-02  1.07540833e-02  2.62367614e-02\n",
      "  -1.09662883e-01 -3.57086509e-02  7.43294284e-02  1.69675669e-03\n",
      "  -9.24099386e-02 -1.23565294e-01 -6.16702400e-02  5.88159598e-02\n",
      "  -3.64866927e-02  8.88293162e-02  1.04467444e-01 -6.52237833e-02\n",
      "   1.38118863e-01  2.11383030e-02  9.56853330e-02  3.46836671e-02\n",
      "  -5.88270053e-02  8.32267404e-02 -9.49602723e-02  3.71114127e-02\n",
      "   2.97985002e-02 -1.11650169e-01 -6.24489263e-02 -1.39175924e-02\n",
      "   2.29521305e-03  3.80262844e-02 -5.83253754e-03  1.36442393e-01\n",
      "   2.24896017e-02  3.16885561e-02  5.81982769e-02 -2.41253637e-02\n",
      "   2.78215110e-02  3.40348892e-02 -9.42610130e-02 -6.76867366e-02\n",
      "  -4.47969176e-02  2.69597881e-02 -4.51286100e-02  1.52183017e-02\n",
      "  -2.77415495e-02  7.01747537e-02 -5.38194664e-02 -1.16572022e-01\n",
      "   1.50123872e-02 -2.53710542e-02 -4.01730947e-02 -1.07358560e-01\n",
      "   3.26252589e-03 -4.59762886e-02  7.30254874e-02 -2.55695451e-03\n",
      "   6.08895458e-02 -1.06824838e-01  3.86044085e-02  7.21649127e-03\n",
      "   2.76189391e-02  3.87012288e-02  4.11925055e-02 -5.88066056e-02]]\n"
     ]
    }
   ],
   "source": [
    "from NeuralSearch.utils.data import convert_example_test\n",
    "\n",
    "# 加载预训练好的无监督语义索引模型 SimCSE\n",
    "params_path='./pretrained/model_20000/model_state.pdparams'\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "# 定义两条文本数据\n",
    "test_data = ['国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据', '语义检索相关的论文']\n",
    "# 给convert_example_test赋予默认值\n",
    "test_func = partial(\n",
    "        convert_example_test,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "# pad对齐操作\n",
    "test_batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # text_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # text_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# conver_example function's input must be dict\n",
    "corpus_ds = MapDataset(test_data)\n",
    "# 构造Dataloader\n",
    "corpus_data_loader = create_dataloader(\n",
    "        corpus_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=test_batchify_fn,\n",
    "        trans_fn=test_func)\n",
    "\n",
    "all_embeddings = []\n",
    "# 切换成eval模式，固定住 dropout\n",
    "model.eval()\n",
    "# 预测的时候不保存梯度\n",
    "with paddle.no_grad():\n",
    "    for batch_data in corpus_data_loader:\n",
    "        input_ids, token_type_ids = batch_data\n",
    "        input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "        token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "        # 抽取向量\n",
    "        text_embeddings = model.get_pooled_embedding(input_ids, token_type_ids)\n",
    "        all_embeddings.append(text_embeddings)\n",
    "\n",
    "text_embedding=all_embeddings[0]\n",
    "print(text_embedding.shape)\n",
    "print(text_embedding.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T03:21:15.713411400Z",
     "start_time": "2024-06-02T03:21:14.267874700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型部署\n",
    "\n",
    "模型部署首先需要把模型转换成静态图模型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path='./output/recall'\n",
    "model.eval()\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "print(save_path)\n",
    "paddle.jit.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from NeuralSearch.utils.data import convert_example_recall_infer\n",
    "from scipy.special import softmax\n",
    "from scipy import spatial\n",
    "\n",
    "class RecallPredictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/output/recall/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/output/recall/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "\n",
    "\n",
    "    def extract_embedding(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        Predicts the data labels.\n",
    "        Args:\n",
    "            data (obj:`List(str)`): The batch data whose each element is a raw text.\n",
    "            tokenizer(obj:`PretrainedTokenizer`): This tokenizer inherits from :class:`~paddlenlp.transformers.PretrainedTokenizer`\n",
    "                which contains most of the methods. Users should refer to the superclass for more information regarding methods.\n",
    "        Returns:\n",
    "            results(obj:`dict`): All the feature vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_recall_infer(text, tokenizer)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        logits = self.output_handle.copy_to_cpu()\n",
    "        return logits\n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        Predicts the data labels.\n",
    "        Args:\n",
    "            data (obj:`List(str)`): The batch data whose each element is a raw text.\n",
    "            tokenizer(obj:`PretrainedTokenizer`): This tokenizer inherits from :class:`~paddlenlp.transformers.PretrainedTokenizer`\n",
    "                which contains most of the methods. Users should refer to the superclass for more information regarding methods.\n",
    "        Returns:\n",
    "            results(obj:`dict`): All the predictions probs.\n",
    "        \"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for idx, text in enumerate(data):\n",
    "            input_ids, segment_ids = convert_example_recall_infer({idx: text[0]}, tokenizer)\n",
    "            title_ids, title_segment_ids = convert_example_recall_infer({\n",
    "                idx: text[1]\n",
    "            }, tokenizer)\n",
    "            examples.append(\n",
    "                (input_ids, segment_ids, title_ids, title_segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        query_ids, query_segment_ids, title_ids, title_segment_ids = batchify_fn(\n",
    "            examples)\n",
    "        self.input_handles[0].copy_from_cpu(query_ids)\n",
    "        self.input_handles[1].copy_from_cpu(query_segment_ids)\n",
    "        self.predictor.run()\n",
    "        query_logits = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        self.input_handles[0].copy_from_cpu(title_ids)\n",
    "        self.input_handles[1].copy_from_cpu(title_segment_ids)\n",
    "        self.predictor.run()\n",
    "        title_logits = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        result = [\n",
    "            float(1 - spatial.distance.cosine(arr1, arr2))\n",
    "            for arr1, arr2 in zip(query_logits, title_logits)\n",
    "        ]\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dir = './output/recall'\n",
    "# device='gpu'\n",
    "device='cpu'\n",
    "max_seq_length=64\n",
    "use_tensorrt = False\n",
    "batch_size =32\n",
    "precision = 'fp32'\n",
    "cpu_threads = 1\n",
    "enable_mkldnn =False\n",
    "predictor = RecallPredictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "\n",
    "\n",
    "id2corpus = {0: '国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据'}\n",
    "corpus_list = [{idx: text} for idx, text in id2corpus.items()]\n",
    "res = predictor.extract_embedding(corpus_list, tokenizer)\n",
    "print('抽取向量')\n",
    "print(res.shape)\n",
    "print(res)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_list = [['中西方语言与文化的差异', '中西方文化差异以及语言体现中西方文化,差异,语言体现'],\n",
    "                   ['中西方语言与文化的差异', '飞桨致力于让深度学习技术的创新与应用更简单']]\n",
    "res = predictor.predict(corpus_list, tokenizer)\n",
    "print('计算相似度')\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
