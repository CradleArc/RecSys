{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "from functools import partial\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 导入python的其他库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.special import expit\n",
    "\n",
    "# 导入Paddle库\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import inference\n",
    "\n",
    "#导入PaddleNLP相关的库\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset, MapDataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from NeuralSearch.utils.data import convert_pairwise_example\n",
    "\n",
    "# 忽略所有警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型构建\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9b52bdae342f4d83ba80f86833d632ada5ed12abd72f4e7e8703002368732351)\n",
    "\n",
    "排序模型是pair-wise的结构，如图所示，query和titile正样本会经过encoder得到一个输出的相似度S1，query和title负样本也会经过Encoder得到一个输出的相似度S2,然后模型根据S1和S2求Triplet损失，其中S1的相似度要大于S2。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 构建读取函数，读取原始数据\n",
    "def read(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        neg_title=row['neg_title']\n",
    "        yield {'query':query, 'title':title,'neg_title':neg_title}\n",
    "\n",
    "def read_test(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        label=row['label']\n",
    "        yield {'query':query, 'title':title,'label':label}\n",
    "\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        # 分布式批采样器加载数据的一个子集。\n",
    "        # 每个进程可以传递给DataLoader一个DistributedBatchSampler的实例，每个进程加载原始数据的一个子集。\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        # 批采样器的基础实现，\n",
    "        # 用于 paddle.io.DataLoader 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    # 组装mini-batch\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "\n",
    "test_file='./dev_ranking_demo.csv'\n",
    "train_file='./train_ranking_demo.csv'\n",
    "\n",
    "train_ds=load_dataset(read,src_path=train_file,lazy=False)\n",
    "dev_ds=load_dataset(read_test,src_path=test_file,lazy=False)\n",
    "print('打印一条训练集')\n",
    "print(train_ds[0])\n",
    "print('打印一条验证集')\n",
    "print(dev_ds[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "比如：对于文本：\n",
    "```\n",
    "个人所得税税务筹划      基于新个税视角下的个人所得税纳税筹划分析新个税;个人所得税;纳税筹划      个人所得税工资薪金税务筹划研究个人所得税,工资薪金,税务筹划\n",
    "```\n",
    "最终构造出来一条正样本对和一条负样本对，如下：\n",
    "\n",
    "```\n",
    "正样本对：[CLS]个人所得税税务筹划[SEP]基于新个税视角下的个人所得税纳税筹划分析新个税;个人所得税;纳税筹划[SEP]\n",
    "负样本对：[CLS]个人所得税税务筹划[SEP]个人所得税工资薪金税务筹划研究个人所得税,工资薪金,税务筹划[SEP]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PairwiseMatching(nn.Layer):\n",
    "    def __init__(self, pretrained_model, dropout=None, margin=0.1):\n",
    "        super().__init__()\n",
    "        self.ptm = pretrained_model\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "        self.margin = margin\n",
    "\n",
    "        # hidden_size -> 1, calculate similarity\n",
    "        self.similarity = nn.Linear(self.ptm.config[\"hidden_size\"], 1)\n",
    "\n",
    "    # 用于导出静态图模型来计算概率\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None):\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                        position_ids, attention_mask)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # 计算相似度\n",
    "        sim = self.similarity(cls_embedding)\n",
    "        return sim\n",
    "\n",
    "\n",
    "    def predict(self,\n",
    "                input_ids,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\n",
    "                                    attention_mask)\n",
    "\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        sim_score = self.similarity(cls_embedding)\n",
    "        sim_score = F.sigmoid(sim_score)\n",
    "        return sim_score\n",
    "\n",
    "    def forward(self,\n",
    "                pos_input_ids,\n",
    "                neg_input_ids,\n",
    "                pos_token_type_ids=None,\n",
    "                neg_token_type_ids=None,\n",
    "                pos_position_ids=None,\n",
    "                neg_position_ids=None,\n",
    "                pos_attention_mask=None,\n",
    "                neg_attention_mask=None):\n",
    "\n",
    "        _, pos_cls_embedding = self.ptm(pos_input_ids, pos_token_type_ids,\n",
    "                                        pos_position_ids, pos_attention_mask)\n",
    "\n",
    "        _, neg_cls_embedding = self.ptm(neg_input_ids, neg_token_type_ids,\n",
    "                                        neg_position_ids, neg_attention_mask)\n",
    "\n",
    "        pos_embedding = self.dropout(pos_cls_embedding)\n",
    "        neg_embedding = self.dropout(neg_cls_embedding)\n",
    "\n",
    "        pos_sim = self.similarity(pos_embedding)\n",
    "        neg_sim = self.similarity(neg_embedding)\n",
    "\n",
    "        pos_sim = F.sigmoid(pos_sim)\n",
    "        neg_sim = F.sigmoid(neg_sim)\n",
    "\n",
    "        labels = paddle.full(\n",
    "            shape=[pos_cls_embedding.shape[0]], fill_value=1.0, dtype='float32')\n",
    "\n",
    "        loss = F.margin_ranking_loss(\n",
    "            pos_sim, neg_sim, labels, margin=self.margin)\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练配置\n",
    "配置模型所需要的一些超参数，实例化模型，优化器等等。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "margin=0.2 # 推荐取值 0.0 ~ 0.2\n",
    "eval_step=100\n",
    "max_seq_length=128\n",
    "epochs=3\n",
    "batch_size=32\n",
    "warmup_proportion=0.0\n",
    "weight_decay=0.0\n",
    "save_step=100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 加载预训练模型 ERNIG-Gram\n",
    "基于 ERNIE-3.0-Medium-zh 热启训练单塔 Pair-wise 排序模型，并定义数据读取的 DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于 ERNIE-3.0-Medium-zh 热启训练单塔 Pair-wise 排序模型，并定义数据读取的 DataLoader\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "\n",
    "trans_func_train = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "trans_func_eval = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"eval\")\n",
    "\n",
    "batchify_fn_train = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pos_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pos_pair_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # neg_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64')  # neg_pair_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "batchify_fn_eval = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pair_segment\n",
    "        Stack(dtype=\"int64\")  # label\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_train,\n",
    "        trans_fn=trans_func_train)\n",
    "\n",
    "dev_data_loader = create_dataloader(\n",
    "        dev_ds,\n",
    "        mode='dev',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_eval,\n",
    "        trans_fn=trans_func_eval)\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练集的数据包含4个Tensor，分别表示的是query和正样本title的input_ids和token_type_ids，以及query和负样本title的input_ids和token_type_ids。\n",
    "\n",
    "验证集则不一样，包含3个Tensor，除了了query后天title拼接成的input_id和token_type_ids的形式为，还有label，表明这条query和title是否相似，1表示的是相似，0表示的是不相似。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型训练\n",
    "\n",
    "下面是模型训练过程，由于在训练的时候使用了评估，所以先构建评估函数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@paddle.no_grad()\n",
    "def evaluate(model, metric, data_loader, phase=\"dev\"):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        # 类别为正的概率\n",
    "        pos_probs = model.predict(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        # 类别为负的概率\n",
    "        neg_probs = 1.0 - pos_probs\n",
    "\n",
    "        preds = np.concatenate((neg_probs, pos_probs), axis=1)\n",
    "        metric.update(preds=preds, labels=labels)\n",
    "\n",
    "    print(\"eval_{} auc:{:.3}\".format(phase, metric.accumulate()))\n",
    "    metric.reset()\n",
    "    model.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面是排序模型的训练过程。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_dir='checkpoint'\n",
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# SimCSE的dropout的参数，也可以使用预训练语言模型默认的dropout参数\n",
    "dropout=0.2\n",
    "# 向量映射的维度，默认的输出是768维，推荐通过线性层映射成256维\n",
    "output_emb_size=256\n",
    "# 训练的epoch数目\n",
    "epochs=1\n",
    "weight_decay=0.0\n",
    "# 学习率\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0\n",
    "\n",
    "def do_train(model,train_data_loader,dev_data_loader):\n",
    "\n",
    "    num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "    lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "    # Generate parameter names needed to perform weight decay.\n",
    "    # All bias and LayerNorm parameters are excluded.\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n",
    "    # 使用AUC作为评估指标\n",
    "    metric = paddle.metric.Auc()\n",
    "\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            pos_input_ids, pos_token_type_ids, neg_input_ids, neg_token_type_ids = batch\n",
    "\n",
    "            loss = model(\n",
    "                pos_input_ids=pos_input_ids,\n",
    "                neg_input_ids=neg_input_ids,\n",
    "                pos_token_type_ids=pos_token_type_ids,\n",
    "                neg_token_type_ids=neg_token_type_ids)\n",
    "            # 每隔10个step打印日志\n",
    "            global_step += 1\n",
    "            if global_step % 10 == 0 :\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            # 反向求梯度\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            # 每隔eval_step进行评估\n",
    "            if global_step % eval_step == 0:\n",
    "                evaluate(model, metric, dev_data_loader, \"dev\")\n",
    "            # 每隔save_steps保存模型\n",
    "            if global_step % save_step == 0:\n",
    "                save_path = os.path.join(save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_path)\n",
    "\n",
    "do_train(model,train_data_loader,dev_data_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 效果评估\n",
    "\n",
    "加载训练好的模型，进行评估。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieGramModel.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieGramTokenizer.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)\n",
    "init_from_ckpt='pretrained/model_30000/model_state.pdparams'\n",
    "state_dict = paddle.load(init_from_ckpt)\n",
    "model.set_dict(state_dict)\n",
    "metric = paddle.metric.Auc()\n",
    "evaluate(model, metric, dev_data_loader, \"dev\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "排序模块用的指标是AUC，随机抽出一对样本，用训练得到的分类起来对两个样本进行预测，预测得到正样本概率>负样本的概率的概率。 一般AUC达到0.7以上就算是不错的，但也要根据任务场景进行分析，有的可能连0.7也达不到，但是效果也是非常不错的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型推理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from NeuralSearch.utils.data import read_text_pair\n",
    "input_file='test_pairwise.csv'\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印一条数据\n",
    "print(valid_ds[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans_func = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"predict\")\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input_ids\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment_ids\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "test_data_loader = create_dataloader(\n",
    "        valid_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "# 打印测试的样本\n",
    "for item in test_data_loader:\n",
    "    print(item)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "\n",
    "    batch_probs = []\n",
    "    model.eval()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids, token_type_ids = batch_data\n",
    "\n",
    "            input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "            token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "            # 输入query title pair得到预测的概率\n",
    "            batch_prob = model.predict(\n",
    "                input_ids=input_ids, token_type_ids=token_type_ids).numpy()\n",
    "\n",
    "            batch_probs.append(batch_prob)\n",
    "        if(len(batch_prob)==1):\n",
    "            batch_probs=np.array(batch_probs)\n",
    "        else:\n",
    "            batch_probs = np.concatenate(batch_probs, axis=0)\n",
    "        return batch_probs\n",
    "\n",
    "\n",
    "\n",
    "y_probs = predict(model, test_data_loader)\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印输出\n",
    "for idx, prob in enumerate(y_probs):\n",
    "    text_pair = valid_ds[idx]\n",
    "    text_pair[\"pred_prob\"] = prob[0]\n",
    "    print(text_pair)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 预测部署\n",
    "\n",
    "首先把动态图模型转换成静态图模型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_path='output/rank'\n",
    "model.eval()\n",
    "\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "paddle.jit.save(model, save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_example_ranking(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "\n",
    "    query, title = example[\"query\"], example[\"title\"]\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义Predictor用于加载静态图的模型参数进行预测。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/output/rank/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/output/rank/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "\n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_ranking(\n",
    "                text,\n",
    "                tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                is_test=True)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        sim_score = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        sim_score = expit(sim_score)\n",
    "\n",
    "        return sim_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "读取测试集的文本，把文本利用convert_example_ranking函数转换成id向量的形式。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_file='test_pairwise.csv'\n",
    "\n",
    "test_ds = load_dataset(read_text_pair,data_path=input_file, lazy=False)\n",
    "\n",
    "data = [{'query': d['query'], 'title': d['title']} for d in test_ds]\n",
    "\n",
    "batches = [\n",
    "        data[idx:idx + batch_size]\n",
    "        for idx in range(0, len(data), batch_size)\n",
    "    ]\n",
    "print(batches[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "实例化Predictor，然后进行预测。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dir='output/rank'\n",
    "device='gpu'\n",
    "max_seq_length=128\n",
    "batch_size=32\n",
    "# 可以安装对应的Tensorrt之后进行加速\n",
    "use_tensorrt=False\n",
    "# 精度，也可以选择fp16，精度几乎无损\n",
    "precision='fp32'\n",
    "# cpu的线程数目\n",
    "cpu_threads=10\n",
    "# 可以在CPU的情况下进行加速\n",
    "enable_mkldnn=False\n",
    "\n",
    "predictor = Predictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "results = []\n",
    "for batch_data in batches:\n",
    "    results.extend(predictor.predict(batch_data, tokenizer))\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t prob: {}'.format(text, results[idx]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
