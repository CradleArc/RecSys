{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "from functools import partial\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 导入python的其他库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.special import expit\n",
    "\n",
    "# 导入Paddle库\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import inference\n",
    "\n",
    "#导入PaddleNLP相关的库\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset, MapDataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from NeuralSearch.utils.data import convert_pairwise_example\n",
    "\n",
    "# 忽略所有警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:03.025049400Z",
     "start_time": "2024-06-11T15:22:03.024541800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型构建\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9b52bdae342f4d83ba80f86833d632ada5ed12abd72f4e7e8703002368732351)\n",
    "\n",
    "排序模型是pair-wise的结构，如图所示，query和titile正样本会经过encoder得到一个输出的相似度S1，query和title负样本也会经过Encoder得到一个输出的相似度S2,然后模型根据S1和S2求Triplet损失，其中S1的相似度要大于S2。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 25292.95it/s]\n",
      "1000it [00:00, 21344.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印一条训练集\n",
      "{'query': '检测干眼', 'title': '诊断干眼的非侵入性新检测技术及应用价值干眼;非侵入性;检测技术;诊断', 'neg_title': '自身免疫性干眼调节T细胞及细胞因子的表达干眼CD4+CD25+Treg细胞,Th17细胞,干燥综合征,细胞因子'}\n",
      "打印一条验证集\n",
      "{'query': '中国特色社会主义文化建设理论', 'title': '建设社会主义文化强国的理论与实践思考社会主义文化强国,社会主义现代化国家,文化建设', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建读取函数，读取原始数据\n",
    "def read(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        neg_title=row['neg_title']\n",
    "        yield {'query':query, 'title':title,'neg_title':neg_title}\n",
    "\n",
    "def read_test(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        label=row['label']\n",
    "        yield {'query':query, 'title':title,'label':label}\n",
    "\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        # 分布式批采样器加载数据的一个子集。\n",
    "        # 每个进程可以传递给DataLoader一个DistributedBatchSampler的实例，每个进程加载原始数据的一个子集。\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        # 批采样器的基础实现，\n",
    "        # 用于 paddle.io.DataLoader 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    # 组装mini-batch\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "\n",
    "test_file='./data/dev_ranking_demo.csv'\n",
    "train_file='./data/train_ranking_demo.csv'\n",
    "\n",
    "train_ds=load_dataset(read,src_path=train_file,lazy=False)\n",
    "dev_ds=load_dataset(read_test,src_path=test_file,lazy=False)\n",
    "print('打印一条训练集')\n",
    "print(train_ds[0])\n",
    "print('打印一条验证集')\n",
    "print(dev_ds[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:29.288706700Z",
     "start_time": "2024-06-11T15:22:29.147147400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "比如：对于文本：\n",
    "```\n",
    "个人所得税税务筹划      基于新个税视角下的个人所得税纳税筹划分析新个税;个人所得税;纳税筹划      个人所得税工资薪金税务筹划研究个人所得税,工资薪金,税务筹划\n",
    "```\n",
    "最终构造出来一条正样本对和一条负样本对，如下：\n",
    "\n",
    "```\n",
    "正样本对：[CLS]个人所得税税务筹划[SEP]基于新个税视角下的个人所得税纳税筹划分析新个税;个人所得税;纳税筹划[SEP]\n",
    "负样本对：[CLS]个人所得税税务筹划[SEP]个人所得税工资薪金税务筹划研究个人所得税,工资薪金,税务筹划[SEP]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class PairwiseMatching(nn.Layer):\n",
    "    def __init__(self, pretrained_model, dropout=None, margin=0.1):\n",
    "        super().__init__()\n",
    "        self.ptm = pretrained_model\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "        self.margin = margin\n",
    "\n",
    "        # hidden_size -> 1, calculate similarity\n",
    "        self.similarity = nn.Linear(self.ptm.config[\"hidden_size\"], 1)\n",
    "\n",
    "    # 用于导出静态图模型来计算概率\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None):\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                        position_ids, attention_mask)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # 计算相似度\n",
    "        sim = self.similarity(cls_embedding)\n",
    "        return sim\n",
    "\n",
    "\n",
    "    def predict(self,\n",
    "                input_ids,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\n",
    "                                    attention_mask)\n",
    "\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        sim_score = self.similarity(cls_embedding)\n",
    "        sim_score = F.sigmoid(sim_score)\n",
    "        return sim_score\n",
    "\n",
    "    def forward(self,\n",
    "                pos_input_ids,\n",
    "                neg_input_ids,\n",
    "                pos_token_type_ids=None,\n",
    "                neg_token_type_ids=None,\n",
    "                pos_position_ids=None,\n",
    "                neg_position_ids=None,\n",
    "                pos_attention_mask=None,\n",
    "                neg_attention_mask=None):\n",
    "\n",
    "        _, pos_cls_embedding = self.ptm(pos_input_ids, pos_token_type_ids,\n",
    "                                        pos_position_ids, pos_attention_mask)\n",
    "\n",
    "        _, neg_cls_embedding = self.ptm(neg_input_ids, neg_token_type_ids,\n",
    "                                        neg_position_ids, neg_attention_mask)\n",
    "\n",
    "        pos_embedding = self.dropout(pos_cls_embedding)\n",
    "        neg_embedding = self.dropout(neg_cls_embedding)\n",
    "\n",
    "        pos_sim = self.similarity(pos_embedding)\n",
    "        neg_sim = self.similarity(neg_embedding)\n",
    "\n",
    "        pos_sim = F.sigmoid(pos_sim)\n",
    "        neg_sim = F.sigmoid(neg_sim)\n",
    "\n",
    "        labels = paddle.full(\n",
    "            shape=[pos_cls_embedding.shape[0]], fill_value=1.0, dtype='float32')\n",
    "\n",
    "        loss = F.margin_ranking_loss(\n",
    "            pos_sim, neg_sim, labels, margin=self.margin)\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:36.443719100Z",
     "start_time": "2024-06-11T15:22:36.432621Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练配置\n",
    "配置模型所需要的一些超参数，实例化模型，优化器等等。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "margin=0.2 # 推荐取值 0.0 ~ 0.2\n",
    "eval_step=100\n",
    "max_seq_length=128\n",
    "epochs=3\n",
    "batch_size=32\n",
    "warmup_proportion=0.0\n",
    "weight_decay=0.0\n",
    "save_step=100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:40.681308600Z",
     "start_time": "2024-06-11T15:22:40.677921800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 加载预训练模型 ERNIG-Gram\n",
    "基于 ERNIE-3.0-Medium-zh 热启训练单塔 Pair-wise 排序模型，并定义数据读取的 DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:51.402140100Z",
     "start_time": "2024-06-11T15:22:44.254819Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-11 23:22:44,239] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:22:44,254] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:22:44,466] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-06-11 23:22:51,337] [ WARNING]\u001B[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieModel: ['ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias', 'ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.norm1.bias']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[33m[2024-06-11 23:22:51,337] [ WARNING]\u001B[0m - Some weights of ErnieModel were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['ernie.pooler.dense.weight', 'ernie.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:22:51,368] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\ernie_3.0_medium_zh_vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:22:51,383] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:22:51,383] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\special_tokens_map.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 基于 ERNIE-3.0-Medium-zh 热启训练单塔 Pair-wise 排序模型，并定义数据读取的 DataLoader\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "\n",
    "trans_func_train = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "trans_func_eval = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"eval\")\n",
    "\n",
    "batchify_fn_train = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pos_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pos_pair_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # neg_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64')  # neg_pair_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "batchify_fn_eval = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pair_segment\n",
    "        Stack(dtype=\"int64\")  # label\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_train,\n",
    "        trans_fn=trans_func_train)\n",
    "\n",
    "dev_data_loader = create_dataloader(\n",
    "        dev_ds,\n",
    "        mode='dev',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_eval,\n",
    "        trans_fn=trans_func_eval)\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练集的数据包含4个Tensor，分别表示的是query和正样本title的input_ids和token_type_ids，以及query和负样本title的input_ids和token_type_ids。\n",
    "\n",
    "验证集则不一样，包含3个Tensor，除了了query后天title拼接成的input_id和token_type_ids的形式为，还有label，表明这条query和title是否相似，1表示的是相似，0表示的是不相似。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型训练\n",
    "\n",
    "下面是模型训练过程，由于在训练的时候使用了评估，所以先构建评估函数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@paddle.no_grad()\n",
    "def evaluate(model, metric, data_loader, phase=\"dev\"):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        # 类别为正的概率\n",
    "        pos_probs = model.predict(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        # 类别为负的概率\n",
    "        neg_probs = 1.0 - pos_probs\n",
    "\n",
    "        preds = np.concatenate((neg_probs, pos_probs), axis=1)\n",
    "        metric.update(preds=preds, labels=labels)\n",
    "\n",
    "    print(\"eval_{} auc:{:.3}\".format(phase, metric.accumulate()))\n",
    "    metric.reset()\n",
    "    model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:51.402140100Z",
     "start_time": "2024-06-11T15:22:51.402140100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面是排序模型的训练过程。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 73\u001B[0m\n\u001B[0;32m     70\u001B[0m                 paddle\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), save_param_path)\n\u001B[0;32m     71\u001B[0m                 tokenizer\u001B[38;5;241m.\u001B[39msave_pretrained(save_path)\n\u001B[1;32m---> 73\u001B[0m \u001B[43mdo_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdev_data_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 43\u001B[0m, in \u001B[0;36mdo_train\u001B[1;34m(model, train_data_loader, dev_data_loader)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_data_loader, start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     41\u001B[0m     pos_input_ids, pos_token_type_ids, neg_input_ids, neg_token_type_ids \u001B[38;5;241m=\u001B[39m batch\n\u001B[1;32m---> 43\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43mneg_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mneg_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m        \u001B[49m\u001B[43mneg_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mneg_token_type_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;66;03m# 每隔10个step打印日志\u001B[39;00m\n\u001B[0;32m     49\u001B[0m     global_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Cell \u001B[1;32mIn[5], line 50\u001B[0m, in \u001B[0;36mPairwiseMatching.forward\u001B[1;34m(self, pos_input_ids, neg_input_ids, pos_token_type_ids, neg_token_type_ids, pos_position_ids, neg_position_ids, pos_attention_mask, neg_attention_mask)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     41\u001B[0m             pos_input_ids,\n\u001B[0;32m     42\u001B[0m             neg_input_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     47\u001B[0m             pos_attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     48\u001B[0m             neg_attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 50\u001B[0m     _, pos_cls_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpos_input_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mpos_position_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_attention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m     _, neg_cls_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mptm(neg_input_ids, neg_token_type_ids,\n\u001B[0;32m     54\u001B[0m                                     neg_position_ids, neg_attention_mask)\n\u001B[0;32m     56\u001B[0m     pos_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pos_cls_embedding)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\ernie\\modeling.py:357\u001B[0m, in \u001B[0;36mErnieModel.forward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, attention_mask, task_type_ids, past_key_values, inputs_embeds, use_cache, output_hidden_states, output_attentions, return_dict)\u001B[0m\n\u001B[0;32m    347\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m    348\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    349\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    353\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m    354\u001B[0m )\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder\u001B[38;5;241m.\u001B[39m_use_cache \u001B[38;5;241m=\u001B[39m use_cache  \u001B[38;5;66;03m# To be consistent with HF\u001B[39;00m\n\u001B[1;32m--> 357\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    364\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, \u001B[38;5;28mtype\u001B[39m(embedding_output)):\n\u001B[0;32m    366\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py:304\u001B[0m, in \u001B[0;36m_transformer_encoder_fwd\u001B[1;34m(self, src, src_mask, cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    292\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m recompute(\n\u001B[0;32m    293\u001B[0m         mod,\n\u001B[0;32m    294\u001B[0m         output,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    301\u001B[0m         output_attentions,\n\u001B[0;32m    302\u001B[0m     )\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 304\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmod\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCache\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer_outputs, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    316\u001B[0m     output \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py:98\u001B[0m, in \u001B[0;36m_transformer_encoder_layer_fwd\u001B[1;34m(self, src, src_mask, cache, output_attentions)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize_before:\n\u001B[0;32m     97\u001B[0m     src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(src)\n\u001B[1;32m---> 98\u001B[0m src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear2\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear1\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m src \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout2(src)\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize_before:\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\common.py:185\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m--> 185\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\functional\\common.py:1960\u001B[0m, in \u001B[0;36mlinear\u001B[1;34m(x, weight, bias, name)\u001B[0m\n\u001B[0;32m   1900\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1901\u001B[0m \n\u001B[0;32m   1902\u001B[0m \u001B[38;5;124;03mFully-connected linear transformation operator. For each input :math:`X` ,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1956\u001B[0m \u001B[38;5;124;03m         [-0.67769694, -0.67769694, -0.67769694, -0.67769694]])\u001B[39;00m\n\u001B[0;32m   1957\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1958\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m in_dynamic_mode():\n\u001B[0;32m   1959\u001B[0m     \u001B[38;5;66;03m# TODO(jiabin): using addmm for fast forward route\u001B[39;00m\n\u001B[1;32m-> 1960\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_C_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1962\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m in_pir_mode():\n\u001B[0;32m   1963\u001B[0m     out \u001B[38;5;241m=\u001B[39m paddle\u001B[38;5;241m.\u001B[39m_pir_ops\u001B[38;5;241m.\u001B[39mmatmul(x, weight, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "save_dir='checkpoint'\n",
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# SimCSE的dropout的参数，也可以使用预训练语言模型默认的dropout参数\n",
    "dropout=0.2\n",
    "# 向量映射的维度，默认的输出是768维，推荐通过线性层映射成256维\n",
    "output_emb_size=256\n",
    "# 训练的epoch数目\n",
    "epochs=1\n",
    "weight_decay=0.0\n",
    "# 学习率\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0\n",
    "\n",
    "def do_train(model,train_data_loader,dev_data_loader):\n",
    "\n",
    "    num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "    lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "    # Generate parameter names needed to perform weight decay.\n",
    "    # All bias and LayerNorm parameters are excluded.\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n",
    "    # 使用AUC作为评估指标\n",
    "    metric = paddle.metric.Auc()\n",
    "\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            pos_input_ids, pos_token_type_ids, neg_input_ids, neg_token_type_ids = batch\n",
    "\n",
    "            loss = model(\n",
    "                pos_input_ids=pos_input_ids,\n",
    "                neg_input_ids=neg_input_ids,\n",
    "                pos_token_type_ids=pos_token_type_ids,\n",
    "                neg_token_type_ids=neg_token_type_ids)\n",
    "            # 每隔10个step打印日志\n",
    "            global_step += 1\n",
    "            if global_step % 10 == 0 :\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            # 反向求梯度\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            # 每隔eval_step进行评估\n",
    "            if global_step % eval_step == 0:\n",
    "                evaluate(model, metric, dev_data_loader, \"dev\")\n",
    "            # 每隔save_steps保存模型\n",
    "            if global_step % save_step == 0:\n",
    "                save_path = os.path.join(save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_path)\n",
    "\n",
    "do_train(model,train_data_loader,dev_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:22:58.622519Z",
     "start_time": "2024-06-11T15:22:53.930109800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 效果评估\n",
    "\n",
    "加载训练好的模型，进行评估。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-11 23:23:05,604] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:05,604] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:08,443] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:16,337] [    INFO]\u001B[0m - All model checkpoint weights were used when initializing ErnieGramModel.\n",
      "\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:16,337] [    INFO]\u001B[0m - All the weights of ErnieGramModel were initialized from the model checkpoint at ernie-gram-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ErnieGramModel for predictions without further training.\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:16,384] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:16,400] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-11 23:23:16,400] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\special_tokens_map.json\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mset_dict(state_dict)\n\u001B[0;32m      9\u001B[0m metric \u001B[38;5;241m=\u001B[39m paddle\u001B[38;5;241m.\u001B[39mmetric\u001B[38;5;241m.\u001B[39mAuc()\n\u001B[1;32m---> 10\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdev\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[0;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[1;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\base\\dygraph\\base.py:352\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>._decorate_function\u001B[1;34m(func, *args, **kwargs)\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;129m@decorator\u001B[39m\u001B[38;5;241m.\u001B[39mdecorator\n\u001B[0;32m    350\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decorate_function\u001B[39m(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 352\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, metric, data_loader, phase)\u001B[0m\n\u001B[0;32m      7\u001B[0m input_ids, token_type_ids, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 类别为正的概率\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m pos_probs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 类别为负的概率\u001B[39;00m\n\u001B[0;32m     11\u001B[0m neg_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m pos_probs\n",
      "Cell \u001B[1;32mIn[5], line 32\u001B[0m, in \u001B[0;36mPairwiseMatching.predict\u001B[1;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     27\u001B[0m             input_ids,\n\u001B[0;32m     28\u001B[0m             token_type_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     29\u001B[0m             position_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     30\u001B[0m             attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 32\u001B[0m     _, cls_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptm\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m     cls_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(cls_embedding)\n\u001B[0;32m     36\u001B[0m     sim_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimilarity(cls_embedding)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\ernie_gram\\modeling.py:315\u001B[0m, in \u001B[0;36mErnieGramModel.forward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, attention_mask, inputs_embeds, past_key_values, use_cache, output_hidden_states, output_attentions, return_dict)\u001B[0m\n\u001B[0;32m    306\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m    307\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    308\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    311\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m    312\u001B[0m )\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder\u001B[38;5;241m.\u001B[39m_use_cache \u001B[38;5;241m=\u001B[39m use_cache  \u001B[38;5;66;03m# To be consistent with HF\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, \u001B[38;5;28mtype\u001B[39m(input_ids)):\n\u001B[0;32m    325\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py:304\u001B[0m, in \u001B[0;36m_transformer_encoder_fwd\u001B[1;34m(self, src, src_mask, cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    292\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m recompute(\n\u001B[0;32m    293\u001B[0m         mod,\n\u001B[0;32m    294\u001B[0m         output,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    301\u001B[0m         output_attentions,\n\u001B[0;32m    302\u001B[0m     )\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 304\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmod\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCache\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer_outputs, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    316\u001B[0m     output \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py:91\u001B[0m, in \u001B[0;36m_transformer_encoder_layer_fwd\u001B[1;34m(self, src, src_mask, cache, output_attentions)\u001B[0m\n\u001B[0;32m     88\u001B[0m     src \u001B[38;5;241m=\u001B[39m attn_outputs\n\u001B[0;32m     89\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 91\u001B[0m src \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout1\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize_before:\n\u001B[0;32m     93\u001B[0m     src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(src)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\common.py:785\u001B[0m, in \u001B[0;36mDropout.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m--> 785\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    786\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m        \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    793\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\functional\\common.py:1140\u001B[0m, in \u001B[0;36mdropout\u001B[1;34m(x, p, axis, training, mode, name)\u001B[0m\n\u001B[0;32m   1137\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m default_main_program()\u001B[38;5;241m.\u001B[39mrandom_seed \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1138\u001B[0m         seed \u001B[38;5;241m=\u001B[39m default_main_program()\u001B[38;5;241m.\u001B[39mrandom_seed\n\u001B[1;32m-> 1140\u001B[0m     out, mask \u001B[38;5;241m=\u001B[39m \u001B[43m_C_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1142\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[0;32m   1151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieGramModel.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieGramTokenizer.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)\n",
    "init_from_ckpt='pretrained/model_30000/model_state.pdparams'\n",
    "state_dict = paddle.load(init_from_ckpt)\n",
    "model.set_dict(state_dict)\n",
    "metric = paddle.metric.Auc()\n",
    "evaluate(model, metric, dev_data_loader, \"dev\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:18.295235500Z",
     "start_time": "2024-06-11T15:23:05.604173200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "排序模块用的指标是AUC，随机抽出一对样本，用训练得到的分类起来对两个样本进行预测，预测得到正样本概率>负样本的概率的概率。 一般AUC达到0.7以上就算是不错的，但也要根据任务场景进行分析，有的可能连0.7也达不到，但是效果也是非常不错的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型推理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。'}\n"
     ]
    }
   ],
   "source": [
    "from NeuralSearch.utils.data import read_text_pair\n",
    "input_file='./data/test_pairwise.csv'\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印一条数据\n",
    "print(valid_ds[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:23.925520100Z",
     "start_time": "2024-06-11T15:25:23.914772200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[5, 53], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 131 , 177 , 405 , 545 , 489 , 116 , 5   , 7   , 19  , 843 , 1767,\n",
      "         113 , 10  , 68  , 73  , 859 , 712 , 12043, 2   , 0   , 0   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 1465, 68  , 73  , 367 , 591 , 86  , 12  , 20  , 68  , 73  , 51  ,\n",
      "         137 , 241 , 812 , 216 , 1043, 3093, 1140, 1465, 68  , 73  , 30  , 12  ,\n",
      "         20  , 68  , 73  , 30  , 241 , 812 , 30  , 1197, 1285, 2   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 158 , 12  , 213 , 58  , 119 , 495 , 68  , 73  , 111 , 38  , 5   ,\n",
      "         859 , 712 , 335 , 514 , 657 , 1197, 1285, 405 , 545 , 30  , 68  , 73  ,\n",
      "         30  , 119 , 495 , 68  , 73  , 111 , 38  , 30  , 461 , 534 , 58  , 220 ,\n",
      "         30  , 1197, 1285, 2   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 12  , 514 , 68  , 73  , 859 , 712 , 51  , 1197, 1285, 5   , 347 ,\n",
      "         639 , 12  , 514 , 68  , 73  , 30  , 859 , 712 , 30  , 1197, 1285, 5   ,\n",
      "         347 , 639 , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 1441, 1140, 68  , 73  , 54  , 405 , 545 , 489 , 116 , 68  , 73  ,\n",
      "         30  , 405 , 545 , 30  , 68  , 73  , 54  , 405 , 545 , 5   , 129 , 135 ,\n",
      "         30  , 68  , 73  , 54  , 405 , 545 , 489 , 116 , 221 , 474 , 30  , 1465,\n",
      "         68  , 73  , 276 , 430 , 2   ]]), Tensor(shape=[5, 53], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])]\n"
     ]
    }
   ],
   "source": [
    "trans_func = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"predict\")\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input_ids\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment_ids\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "test_data_loader = create_dataloader(\n",
    "        valid_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "# 打印测试的样本\n",
    "for item in test_data_loader:\n",
    "    print(item)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:25:27.560230700Z",
     "start_time": "2024-06-11T15:25:27.551769500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。', 'pred_prob': 0.8511221}\n",
      "{'query': '中西方语言与文化的差异', 'title': '跨文化视角下中国文化对外传播路径琐谈跨文化,中国文化,传播,翻译', 'pred_prob': 0.7862962}\n",
      "{'query': '中西方语言与文化的差异', 'title': '从中西方民族文化心理的差异看英汉翻译语言,文化,民族文化心理,思维方式,翻译', 'pred_prob': 0.91767514}\n",
      "{'query': '中西方语言与文化的差异', 'title': '中英文化差异对翻译的影响中英文化,差异,翻译的影响', 'pred_prob': 0.8601747}\n",
      "{'query': '中西方语言与文化的差异', 'title': '浅谈文化与语言习得文化,语言,文化与语言的关系,文化与语言习得意识,跨文化交际', 'pred_prob': 0.8944413}\n"
     ]
    }
   ],
   "source": [
    "def predict(model, data_loader):\n",
    "\n",
    "    batch_probs = []\n",
    "    model.eval()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids, token_type_ids = batch_data\n",
    "\n",
    "            input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "            token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "            # 输入query title pair得到预测的概率\n",
    "            batch_prob = model.predict(\n",
    "                input_ids=input_ids, token_type_ids=token_type_ids).numpy()\n",
    "\n",
    "            batch_probs.append(batch_prob)\n",
    "        if(len(batch_prob)==1):\n",
    "            batch_probs=np.array(batch_probs)\n",
    "        else:\n",
    "            batch_probs = np.concatenate(batch_probs, axis=0)\n",
    "        return batch_probs\n",
    "\n",
    "\n",
    "\n",
    "y_probs = predict(model, test_data_loader)\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印输出\n",
    "for idx, prob in enumerate(y_probs):\n",
    "    text_pair = valid_ds[idx]\n",
    "    text_pair[\"pred_prob\"] = prob[0]\n",
    "    print(text_pair)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:26:00.627400500Z",
     "start_time": "2024-06-11T15:25:59.772046500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 预测部署\n",
    "\n",
    "首先把动态图模型转换成静态图模型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "output_path='output/rank'\n",
    "model.eval()\n",
    "\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "paddle.jit.save(model, save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:26:17.288601600Z",
     "start_time": "2024-06-11T15:26:07.028705100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def convert_example_ranking(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "\n",
    "    query, title = example[\"query\"], example[\"title\"]\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:26:20.601756800Z",
     "start_time": "2024-06-11T15:26:20.575258600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义Predictor用于加载静态图的模型参数进行预测。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/output/rank/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/output/rank/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "\n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_ranking(\n",
    "                text,\n",
    "                tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                is_test=True)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        sim_score = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        sim_score = expit(sim_score)\n",
    "\n",
    "        return sim_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:26:26.386342700Z",
     "start_time": "2024-06-11T15:26:26.386342700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "读取测试集的文本，把文本利用convert_example_ranking函数转换成id向量的形式。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。'}, {'query': '中西方语言与文化的差异', 'title': '跨文化视角下中国文化对外传播路径琐谈跨文化,中国文化,传播,翻译'}, {'query': '中西方语言与文化的差异', 'title': '从中西方民族文化心理的差异看英汉翻译语言,文化,民族文化心理,思维方式,翻译'}, {'query': '中西方语言与文化的差异', 'title': '中英文化差异对翻译的影响中英文化,差异,翻译的影响'}, {'query': '中西方语言与文化的差异', 'title': '浅谈文化与语言习得文化,语言,文化与语言的关系,文化与语言习得意识,跨文化交际'}]\n"
     ]
    }
   ],
   "source": [
    "input_file='./data/test_pairwise.csv'\n",
    "\n",
    "test_ds = load_dataset(read_text_pair,data_path=input_file, lazy=False)\n",
    "\n",
    "data = [{'query': d['query'], 'title': d['title']} for d in test_ds]\n",
    "\n",
    "batches = [\n",
    "        data[idx:idx + batch_size]\n",
    "        for idx in range(0, len(data), batch_size)\n",
    "    ]\n",
    "print(batches[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:26:33.477097400Z",
     "start_time": "2024-06-11T15:26:33.471540200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "实例化Predictor，然后进行预测。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。'} \t prob: [0.8511221]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '跨文化视角下中国文化对外传播路径琐谈跨文化,中国文化,传播,翻译'} \t prob: [0.78629637]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '从中西方民族文化心理的差异看英汉翻译语言,文化,民族文化心理,思维方式,翻译'} \t prob: [0.91767514]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '中英文化差异对翻译的影响中英文化,差异,翻译的影响'} \t prob: [0.86017483]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '浅谈文化与语言习得文化,语言,文化与语言的关系,文化与语言习得意识,跨文化交际'} \t prob: [0.8944415]\n"
     ]
    }
   ],
   "source": [
    "model_dir='output/rank'\n",
    "device='gpu'\n",
    "max_seq_length=128\n",
    "batch_size=32\n",
    "# 可以安装对应的Tensorrt之后进行加速\n",
    "use_tensorrt=False\n",
    "# 精度，也可以选择fp16，精度几乎无损\n",
    "precision='fp32'\n",
    "# cpu的线程数目\n",
    "cpu_threads=10\n",
    "# 可以在CPU的情况下进行加速\n",
    "enable_mkldnn=False\n",
    "\n",
    "predictor = Predictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "results = []\n",
    "for batch_data in batches:\n",
    "    results.extend(predictor.predict(batch_data, tokenizer))\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t prob: {}'.format(text, results[idx]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T15:26:39.729824500Z",
     "start_time": "2024-06-11T15:26:38.244141200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
