{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在项目开始之前，我们首先导入相关的库包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "import abc\n",
    "import sys\n",
    "from functools import partial\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "# 导入python的其他库\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "# 导入Paddle库\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import inference\n",
    "\n",
    "#导入PaddleNLP相关的库\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset, MapDataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from paddlenlp.utils.downloader import get_path_from_url\n",
    "from visualdl import LogWriter\n",
    "from utils.data import convert_pairwise_example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据读取逻辑\n",
    "def read_simcse_text(data_path):\n",
    "    \"\"\"Reads data.\"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if i==0:\n",
    "                continue\n",
    "            data = line.rstrip()\n",
    "            # 这里的text_a和text_b是一样的\n",
    "            yield {'text_a': data, 'text_b': data}\n",
    "\n",
    "train_set_file='./train_demo.csv'\n",
    "train_ds = load_dataset(read_simcse_text, data_path=train_set_file, lazy=False)\n",
    "# 展示3条数据\n",
    "for i  in range(3):\n",
    "    print(train_ds[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 构建Dataloader\n",
    "\n",
    "在训练神经网络之前，我们需要构建小批量的数据，所以需要借助Dataloader,在组装小批量的数据的之前我们认识一下下面的API:\n",
    "\n",
    "| API                             | 简介                                       |\n",
    "| ------------------------------- | :----------------------------------------- |\n",
    "| `paddlenlp.data.Stack`          | 堆叠N个具有相同shape的输入数据来构建一个batch |\n",
    "| `paddlenlp.data.Pad`            | 将长度不同的多个句子padding到统一长度，取N个输入数据中的最大长度 |\n",
    "| `paddlenlp.data.Tuple`          | 将多个batchify函数包装在一起 |\n",
    "\n",
    "更多数据处理操作详见： [https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 由于文本是序列数据，数据对齐。如下面会对每个序列补0，和a的长度保持一致\n",
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7]\n",
    "c = [8, 9]\n",
    "result = Pad(pad_val=0)([a, b, c])\n",
    "print(\"Padded Data: \\n\", result)\n",
    "print()\n",
    "\n",
    "# 组装minibatch需要使用\n",
    "a = [1, 2, 3, 4]\n",
    "b = [3, 4, 5, 6]\n",
    "c = [5, 6, 7, 8]\n",
    "result = Stack()([a, b, c])\n",
    "print(\"Stacked Data: \\n\", result)\n",
    "print()\n",
    "\n",
    "data = [\n",
    "        [[1, 2, 3, 4], [1]],\n",
    "        [[5, 6, 7], [0]],\n",
    "        [[8, 9], [1]],\n",
    "       ]\n",
    "batchify_fn = Tuple(Pad(pad_val=0), Stack())\n",
    "ids, labels = batchify_fn(data)\n",
    "print(\"ids: \\n\", ids)\n",
    "print()\n",
    "print(\"labels: \\n\", labels)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 明文数据 -> ID 序列训练数据\n",
    "\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        # 分布式批采样器加载数据的一个子集。\n",
    "        # 每个进程可以传递给DataLoader一个DistributedBatchSampler的实例，每个进程加载原始数据的一个子集。\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        # 批采样器的基础实现，\n",
    "        # 用于 paddle.io.DataLoader 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    # 组装mini-batch\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "def convert_example(example, tokenizer, max_seq_length=512, do_evalute=False):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for key, text in example.items():\n",
    "        if 'label' in key:\n",
    "            # do_evaluate\n",
    "            result += [example['label']]\n",
    "        else:\n",
    "            # do_train\n",
    "            encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "            input_ids = encoded_inputs[\"input_ids\"]\n",
    "            token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "            result += [input_ids, token_type_ids]\n",
    "\n",
    "    return result\n",
    "\n",
    "# 语义索引的维度最大为64，可以根据自己的情况调节长度\n",
    "max_seq_length=64\n",
    "# 根据经验 batch_size越大效果越好\n",
    "batch_size=32\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-3.0-medium-zh')\n",
    "# 给convert_example赋予默认的值，如tokenizer，max_seq_length\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "# [pad]对齐的函数\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # query_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # query_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # title_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # tilte_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# 构建训练的Dataloader\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "展示一下输入的dataloader的数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:10.495118Z",
     "iopub.status.busy": "2022-09-09T12:37:10.494741Z",
     "iopub.status.idle": "2022-09-09T12:37:11.793570Z",
     "shell.execute_reply": "2022-09-09T12:37:11.792526Z",
     "shell.execute_reply.started": "2022-09-09T12:37:10.495094Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:36:38.433031700Z",
     "start_time": "2024-06-01T07:36:38.346709900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[32, 62], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1    , 12056, 1441 , ..., 0    , 0    , 0    ],\n",
      "        [1    , 338  , 3003 , ..., 0    , 0    , 0    ],\n",
      "        [1    , 32   , 159  , ..., 0    , 0    , 0    ],\n",
      "        ...,\n",
      "        [1    , 296  , 242  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 19   , 266  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 12056, 1441 , ..., 0    , 0    , 0    ]]), Tensor(shape=[32, 62], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]), Tensor(shape=[32, 62], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1    , 12056, 1441 , ..., 0    , 0    , 0    ],\n",
      "        [1    , 338  , 3003 , ..., 0    , 0    , 0    ],\n",
      "        [1    , 32   , 159  , ..., 0    , 0    , 0    ],\n",
      "        ...,\n",
      "        [1    , 296  , 242  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 19   , 266  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 12056, 1441 , ..., 0    , 0    , 0    ]]), Tensor(shape=[32, 62], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1865: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_data_loader):\n",
    "    if idx == 0:\n",
    "        print(batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面展示的是一个batch的数据，包含两个Tensor，第一个Tensor表示的是input_ids，第二个Tensor表示的是token_type_ids；第一个Tensor中，32是batch_size的维度，64代表的是序列的长度，表示输入的文本的最大长度是64；第二个Tensor中，32表示的也是batch_size，64表示的是序列的长度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型构建\n",
    "\n",
    "接下来搭建SimCSE模型，主要部分是用query和title分别得到embedding向量，然后计算余弦相似度。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fa84f7db963c4efd82b971f3ef477c070e5300acee3e4e788b4a6c56dd31c003)\n",
    "\n",
    "\n",
    "上图是SimCSE的原理图，SimCSE主要是通过dropout来把同一个句子变成正样本（做两次前向，但是dropout有随机因素，所以产生的向量不一样，但是本质上还是表示的是同一句话），把一个batch里面其他的句子变成负样本的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:11.795726Z",
     "iopub.status.busy": "2022-09-09T12:37:11.795247Z",
     "iopub.status.idle": "2022-09-09T12:37:11.810467Z",
     "shell.execute_reply": "2022-09-09T12:37:11.809582Z",
     "shell.execute_reply.started": "2022-09-09T12:37:11.795695Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:36:42.741552Z",
     "start_time": "2024-06-01T07:36:42.723649600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\n",
      "You can set full_graph=True, then you can assign input spec.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class SimCSE(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 pretrained_model,\n",
    "                 dropout=None,\n",
    "                 margin=0.0,\n",
    "                 scale=20,\n",
    "                 output_emb_size=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptm = pretrained_model\n",
    "        # 显式的加一个dropout来控制\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "\n",
    "        # if output_emb_size is greater than 0, then add Linear layer to reduce embedding_size, \n",
    "        # 考虑到性能和效率，我们推荐把output_emb_size设置成256\n",
    "        # 向量越大，语义信息越丰富，但消耗资源越多\n",
    "        self.output_emb_size = output_emb_size\n",
    "        if output_emb_size > 0:\n",
    "            weight_attr = paddle.ParamAttr(\n",
    "                initializer=nn.initializer.TruncatedNormal(std=0.02))\n",
    "            self.emb_reduce_linear = paddle.nn.Linear(\n",
    "                768, output_emb_size, weight_attr=weight_attr)\n",
    "\n",
    "        self.margin = margin\n",
    "        # 为了使余弦相似度更容易收敛，我们选择把计算出来的余弦相似度扩大scale倍，一般设置成20左右\n",
    "        self.sacle = scale\n",
    "\n",
    "    # 加入jit注释能够把该提取向量的函数导出成静态图\n",
    "    # 对应input_id,token_type_id两个\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None,\n",
    "                             with_pooler=True):\n",
    "\n",
    "        # Note: cls_embedding is poolerd embedding with act tanh \n",
    "        sequence_output, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                                  position_ids, attention_mask)\n",
    "\n",
    "        if with_pooler == False:\n",
    "            cls_embedding = sequence_output[:, 0, :]\n",
    "\n",
    "        if self.output_emb_size > 0:\n",
    "            cls_embedding = self.emb_reduce_linear(cls_embedding)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/functional/normalize_cn.html\n",
    "        cls_embedding = F.normalize(cls_embedding, p=2, axis=-1)\n",
    "        return cls_embedding\n",
    "\n",
    "    def forward(self,\n",
    "                query_input_ids,\n",
    "                title_input_ids,\n",
    "                query_token_type_ids=None,\n",
    "                query_position_ids=None,\n",
    "                query_attention_mask=None,\n",
    "                title_token_type_ids=None,\n",
    "                title_position_ids=None,\n",
    "                title_attention_mask=None):\n",
    "        \n",
    "        # 第 1 次编码: 文本经过无监督语义索引模型编码后的语义向量 \n",
    "        # [N, 768]\n",
    "        query_cls_embedding = self.get_pooled_embedding(\n",
    "            query_input_ids, query_token_type_ids, query_position_ids,\n",
    "            query_attention_mask)\n",
    "\n",
    "        # 第 2 次编码: 文本经过无监督语义索引模型编码后的语义向量 \n",
    "        # [N, 768]\n",
    "        title_cls_embedding = self.get_pooled_embedding(\n",
    "            title_input_ids, title_token_type_ids, title_position_ids,\n",
    "            title_attention_mask)\n",
    "\n",
    "        # 相似度矩阵: [N, N]\n",
    "        cosine_sim = paddle.matmul(\n",
    "            query_cls_embedding, title_cls_embedding, transpose_y=True)\n",
    "\n",
    "        # substract margin from all positive samples cosine_sim()\n",
    "        # 填充self.margin值，比如margin为0.2，query_cls_embedding.shape[0]=2 \n",
    "        # margin_diag: [0.2,0.2]\n",
    "        margin_diag = paddle.full(\n",
    "            shape=[query_cls_embedding.shape[0]],\n",
    "            fill_value=self.margin,\n",
    "            dtype=paddle.get_default_dtype())\n",
    "        # input paddle.diag(margin_diag): [[0.2,0],[0,0.2]]\n",
    "        # input cosine_sim : [[1.0,0.6],[0.6,1.0]]\n",
    "        # output cosine_sim: [[0.8,0.6],[0.6,0.8]]\n",
    "        cosine_sim = cosine_sim - paddle.diag(margin_diag)\n",
    "\n",
    "        # scale cosine to ease training converge\n",
    "        cosine_sim *= self.sacle\n",
    "\n",
    "        # 转化成多分类任务: 对角线元素是正例，其余元素为负例\n",
    "        # labels : [0,1,2,3]\n",
    "        labels = paddle.arange(0, query_cls_embedding.shape[0], dtype='int64')\n",
    "        # labels : [[0],[1],[2],[3]]\n",
    "        labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "\n",
    "        # 交叉熵损失函数\n",
    "        loss = F.cross_entropy(input=cosine_sim, label=labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "上述代码的相似度矩阵计算示例如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/abf8d97a72d34eefafe6610b63aba654bdf853bf5aae4f4287ca7e2d83beab63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练配置\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:11.812238Z",
     "iopub.status.busy": "2022-09-09T12:37:11.811684Z",
     "iopub.status.idle": "2022-09-09T12:37:11.817084Z",
     "shell.execute_reply": "2022-09-09T12:37:11.816290Z",
     "shell.execute_reply.started": "2022-09-09T12:37:11.812212Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:36:46.961257700Z",
     "start_time": "2024-06-01T07:36:46.939652300Z"
    }
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# SimCSE的dropout的参数，也可以使用预训练语言模型默认的dropout参数\n",
    "dropout=0.2\n",
    "# 向量映射的维度，默认的输出是768维，推荐通过线性层映射成256维\n",
    "output_emb_size=256\n",
    "# 训练的epoch数目\n",
    "epochs=1\n",
    "weight_decay=0.0\n",
    "# 学习率\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练模型\n",
    "1. 加载预训练模型 ERNIE 3.0-Medium 进行热启\n",
    "2. 定义优化器 AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:11.818683Z",
     "iopub.status.busy": "2022-09-09T12:37:11.818434Z",
     "iopub.status.idle": "2022-09-09T12:37:13.125176Z",
     "shell.execute_reply": "2022-09-09T12:37:13.124065Z",
     "shell.execute_reply.started": "2022-09-09T12:37:11.818660Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:36:58.735357700Z",
     "start_time": "2024-06-01T07:36:50.728423900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-01 15:36:50,728] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:36:50,729] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:36:51,176] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:36:58,673] [ WARNING]\u001B[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieModel: ['ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:36:58,674] [ WARNING]\u001B[0m - Some weights of ErnieModel were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['ernie.pooler.dense.bias', 'ernie.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ernie-3.0-medium-zh\n"
     ]
    }
   ],
   "source": [
    "# 设置 ERNIE-3.0-Medium-zh 预训练模型\n",
    "model_name_or_path='ernie-3.0-medium-zh'\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "       model_name_or_path,\n",
    "       hidden_dropout_prob=dropout,\n",
    "       attention_probs_dropout_prob=dropout)\n",
    "print(\"loading model from {}\".format(model_name_or_path))\n",
    "\n",
    "# 实例化SimCSE，SimCSE使用的Encoder是ERNIE-3.0-Medium-zh\n",
    "model = SimCSE(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "# 训练的总步数\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "# warmpup操作，学习率先上升后下降\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "# 设置优化器\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练\n",
    "\n",
    "上面的训练配置完毕以后，下面就可以开始训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:13.127401Z",
     "iopub.status.busy": "2022-09-09T12:37:13.126688Z",
     "iopub.status.idle": "2022-09-09T12:37:19.514332Z",
     "shell.execute_reply": "2022-09-09T12:37:19.513241Z",
     "shell.execute_reply.started": "2022-09-09T12:37:13.127370Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir='checkpoint'\n",
    "save_steps=100\n",
    "time_start=time.time()\n",
    "global_step = 0\n",
    "tic_train = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        query_input_ids, query_token_type_ids, title_input_ids, title_token_type_ids = batch\n",
    "        # 其中query和title为同一条数据\n",
    "        loss = model(\n",
    "                query_input_ids=query_input_ids,\n",
    "                title_input_ids=title_input_ids,\n",
    "                query_token_type_ids=query_token_type_ids,\n",
    "                title_token_type_ids=title_token_type_ids)\n",
    "        # 每隔10个step进行打印日志\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        # 反向\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "        # 每隔save_steps保存模型\n",
    "        if global_step % save_steps == 0:\n",
    "            save_path = os.path.join(save_dir, \"model_%d\" % (global_step))\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "            paddle.save(model.state_dict(), save_param_path)\n",
    "            tokenizer.save_pretrained(save_path)\n",
    "time_end=time.time()\n",
    "print('totally cost {} seconds'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型预测\n",
    "\n",
    "由于本项目使用的demo数据，在预测部分为了保证效果，我们使用已经用全量数据训练好的模型，首先下载训练好的SimCSE模型，然后进行解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:19.519303Z",
     "iopub.status.busy": "2022-09-09T12:37:19.518600Z",
     "iopub.status.idle": "2022-09-09T12:37:23.893347Z",
     "shell.execute_reply": "2022-09-09T12:37:23.892078Z",
     "shell.execute_reply.started": "2022-09-09T12:37:19.519274Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:37:10.596188900Z",
     "start_time": "2024-06-01T07:37:10.553896300Z"
    }
   },
   "outputs": [],
   "source": [
    "if(not os.path.exists('simcse_model.zip')):\n",
    "    get_path_from_url('https://bj.bcebos.com/v1/paddlenlp/models/simcse_model.zip',root_dir='.')\n",
    "# 解压SimCSE模型\n",
    "# !unzip -o simcse_model.zip -d pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:23.895441Z",
     "iopub.status.busy": "2022-09-09T12:37:23.895107Z",
     "iopub.status.idle": "2022-09-09T12:37:24.792916Z",
     "shell.execute_reply": "2022-09-09T12:37:24.791860Z",
     "shell.execute_reply.started": "2022-09-09T12:37:23.895414Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:37:16.374366800Z",
     "start_time": "2024-06-01T07:37:14.782363900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for ptm.embeddings.word_embeddings.weight. ptm.embeddings.word_embeddings.weight receives a shape [18000, 768], but the expected shape is [40000, 768].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for ptm.embeddings.position_embeddings.weight. ptm.embeddings.position_embeddings.weight receives a shape [513, 768], but the expected shape is [2048, 768].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for ptm.embeddings.token_type_embeddings.weight. ptm.embeddings.token_type_embeddings.weight receives a shape [2, 768], but the expected shape is [4, 768].\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for ptm.embeddings.task_type_embeddings.weight. ptm.embeddings.task_type_embeddings.weight is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\n",
      "You can set full_graph=True, then you can assign input spec.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 256]\n",
      "[[-2.38936171e-02 -1.86179597e-02 -3.87326293e-02 -2.14510243e-02\n",
      "   5.80730699e-02 -7.30442628e-02  4.47707027e-02 -4.79865447e-03\n",
      "  -1.11777507e-01  3.06986496e-02 -7.58780241e-02 -1.39245540e-02\n",
      "  -3.18336859e-02  7.34863579e-02 -6.20127991e-02 -7.75121376e-02\n",
      "  -2.94753723e-02 -1.10602945e-01  1.43525824e-02  7.38698058e-03\n",
      "  -6.20281848e-04 -1.13605276e-01  5.09278849e-03  1.68028884e-02\n",
      "  -9.10069644e-02 -4.97759227e-03  9.68626812e-02 -4.01212536e-02\n",
      "  -4.31677513e-02 -6.29915670e-02 -2.77599022e-02 -1.28067151e-01\n",
      "   4.59447299e-04  1.12159485e-02 -2.34453306e-02 -1.29382834e-02\n",
      "  -9.12685394e-02  8.15406442e-02 -7.75527675e-03  3.35520543e-02\n",
      "  -7.50929788e-02 -6.48786947e-02  8.32832009e-02 -3.95188704e-02\n",
      "   1.33434922e-01 -7.62892142e-02  2.10594863e-01  9.67187062e-02\n",
      "  -4.11144681e-02  5.90532506e-03  2.87344866e-02 -1.25124678e-01\n",
      "  -9.30405185e-02 -1.03214726e-01  1.13968330e-03 -1.43238613e-02\n",
      "   9.50518623e-02 -1.65595077e-02 -4.30812314e-02  5.52676395e-02\n",
      "  -8.95094573e-02 -4.99802046e-02  2.48110220e-02 -1.93514246e-02\n",
      "   4.94862050e-02 -1.09978030e-02  3.30754779e-02 -8.02364871e-02\n",
      "  -7.09240213e-02  1.38881326e-01  1.55964484e-02  7.00399280e-02\n",
      "   4.87305410e-02 -3.24490219e-02 -6.10601828e-02 -9.60236508e-03\n",
      "  -7.82980770e-03 -1.70542430e-02 -3.72621194e-02  1.37725875e-01\n",
      "   1.55777242e-02 -7.80158152e-04 -4.65260260e-02 -7.25548267e-02\n",
      "   4.32729125e-02 -1.60146758e-01 -1.33182392e-01  9.39990208e-02\n",
      "  -5.65836951e-02  2.47459672e-02 -1.41402697e-02  3.96334231e-02\n",
      "   1.86874848e-02 -6.52665598e-03 -1.52942557e-02 -2.80678812e-02\n",
      "  -1.44324386e-02  9.96803418e-02  1.14819976e-02  2.26326417e-02\n",
      "  -1.88915452e-04 -3.69913802e-02 -5.13089262e-03  4.94119376e-02\n",
      "  -1.81786641e-02 -5.45423068e-02  2.44810227e-02  2.83814147e-02\n",
      "  -6.98113218e-02  9.37126502e-02 -2.98217200e-02 -3.92348915e-02\n",
      "   8.00552145e-02  3.25043350e-02 -2.96206418e-02 -5.61116748e-02\n",
      "  -4.70948704e-02 -8.08036774e-02 -7.62376860e-02  3.50234993e-02\n",
      "  -4.82863486e-02  5.54802194e-02 -1.09671557e-03  5.13044046e-03\n",
      "  -2.49400754e-02 -2.22539715e-02 -5.44783077e-04  4.51335907e-02\n",
      "   7.01561439e-05 -4.05995324e-02 -4.29379493e-02  3.79059166e-02\n",
      "   6.30532112e-03  6.31587952e-02  4.98235738e-03 -5.83176464e-02\n",
      "  -6.86376775e-03 -2.41296608e-02  4.68463153e-02 -3.49179246e-02\n",
      "   5.22721931e-02  1.13000028e-01 -3.63280550e-02 -5.63905351e-02\n",
      "   2.48677395e-02 -6.62251748e-03  1.03345588e-01 -9.29605775e-03\n",
      "   1.05893448e-01  6.61475062e-02 -2.14430355e-02 -3.44023295e-02\n",
      "   6.00234903e-02 -7.71017000e-02 -2.96891835e-02  3.57352346e-02\n",
      "  -2.43359208e-02  2.02705828e-03 -1.04504988e-01  7.09457994e-02\n",
      "  -5.85845113e-02  1.24924876e-01  7.78270066e-02 -1.95585545e-02\n",
      "   3.71500850e-02  5.04037067e-02  2.42853910e-02 -1.63062885e-02\n",
      "   7.55493790e-02 -8.22982751e-03  1.67472418e-02  4.17400114e-02\n",
      "   1.35832326e-02  1.05556801e-01 -4.44971807e-02  4.06498909e-02\n",
      "   1.18971400e-01  6.96983784e-02  4.82908711e-02 -8.89302865e-02\n",
      "  -8.10411107e-03 -2.27572094e-03 -4.19332944e-02 -3.53009962e-02\n",
      "   3.26378904e-02 -5.29955067e-02 -7.61810644e-03 -6.74278140e-02\n",
      "   3.21941376e-02  1.14661768e-01  2.74233967e-02  9.31852534e-02\n",
      "   1.07308896e-03  1.37721360e-01 -6.28966093e-02  3.04301027e-02\n",
      "  -1.84148774e-01 -8.67449343e-02  2.34652534e-02 -3.60179953e-02\n",
      "  -1.00319915e-01  4.44446802e-02 -7.72560388e-02  2.41001565e-02\n",
      "   7.44484439e-02  7.28243515e-02 -7.59818079e-03 -2.68514808e-02\n",
      "   1.23978123e-01  1.05049245e-01  1.17334826e-02 -6.96398467e-02\n",
      "  -4.13490906e-02  1.55874878e-01 -3.61632966e-02  4.39834818e-02\n",
      "  -6.35272940e-04 -9.51310843e-02 -1.75053068e-02  2.32684333e-02\n",
      "   3.60063538e-02  3.92234214e-02  1.78328101e-02 -2.34217923e-02\n",
      "  -1.78714380e-01 -8.96904916e-02 -3.32743116e-02  1.57977901e-02\n",
      "  -1.12955486e-02  1.83391999e-02  6.13671020e-02 -2.65253820e-02\n",
      "   4.08442505e-02  1.39107474e-03 -3.09836436e-02 -4.01387326e-02\n",
      "   3.94170545e-02  1.01407589e-02 -2.44590989e-03  2.67459024e-02\n",
      "   4.04687561e-02  9.23904777e-02 -6.14426807e-02 -6.31493405e-02\n",
      "   7.95214027e-02  6.45805523e-02 -3.13493200e-02  4.57527339e-02\n",
      "   7.49894157e-02  5.74484318e-02 -2.30828952e-02  4.22420464e-02\n",
      "   9.47391465e-02  9.97768790e-02  1.16430512e-02 -3.26821208e-02]\n",
      " [ 5.98876476e-02 -4.67539625e-03 -1.10207640e-01  3.38299274e-02\n",
      "   2.43929010e-02 -1.01046577e-01  4.29728534e-03  4.00339998e-02\n",
      "  -9.19079259e-02 -5.83520830e-02 -2.29058228e-02  7.81192109e-02\n",
      "  -4.08819970e-03  8.01766813e-02  5.24296761e-02 -1.00533860e-02\n",
      "   7.00081885e-02 -1.07360668e-01 -4.67482302e-03  1.15130663e-01\n",
      "  -1.76248346e-02 -5.94091564e-02  1.74166691e-02  2.30180882e-02\n",
      "   1.12048514e-01 -8.61317888e-02  5.68966791e-02 -3.57455984e-02\n",
      "   5.07172756e-03 -8.90962183e-02  7.01211914e-02  4.55992743e-02\n",
      "  -5.80560789e-03 -5.23530059e-02  1.51730068e-02  1.36996210e-01\n",
      "  -1.34410992e-01  3.30460956e-03  1.79281435e-03 -9.53789055e-02\n",
      "  -1.22772558e-02 -4.63729016e-02  6.99983537e-03 -3.32532898e-02\n",
      "   4.25921082e-02 -9.81957763e-02  1.21257454e-01  1.42998964e-01\n",
      "   3.50143574e-02 -9.85023007e-03  4.18281667e-02  5.82434162e-02\n",
      "   5.52991815e-02 -7.03922138e-02 -9.57520753e-02  9.46803391e-03\n",
      "   1.16223864e-01  2.80151851e-02 -3.30251902e-02 -5.84641211e-02\n",
      "  -3.38980965e-02 -6.48537055e-02  2.15261150e-02 -1.16891429e-01\n",
      "   6.29716218e-02  1.04986660e-01  3.03404778e-02  4.87276763e-02\n",
      "   1.46824587e-02  7.04762817e-04 -1.04485499e-02  1.71457008e-02\n",
      "   5.38535556e-03  6.86078891e-02 -4.83981567e-03 -8.79398137e-02\n",
      "   1.05693221e-01 -2.24042777e-02 -5.23625948e-02  1.24127403e-01\n",
      "   4.07421179e-02  6.81212768e-02 -3.91257815e-02  3.89558002e-02\n",
      "   2.37337258e-02 -3.07243653e-02 -1.22316152e-01  2.47302298e-02\n",
      "  -7.98637792e-02  6.67086476e-03  1.22887287e-02  9.22031999e-02\n",
      "   6.00558855e-02 -5.92697635e-02  1.22830197e-02 -2.00812370e-02\n",
      "  -2.19404344e-02  3.72038037e-02 -5.07596470e-02  5.85647821e-02\n",
      "   4.26812097e-02  2.86342651e-02 -9.98381674e-02  1.07276268e-01\n",
      "  -1.93709098e-02  1.80898439e-02 -2.07656417e-02  1.08140670e-01\n",
      "   2.56591639e-03  1.18653879e-01  3.11301500e-02  2.12134197e-02\n",
      "  -5.46023156e-03 -1.09993279e-01  4.14523147e-02 -7.17517138e-02\n",
      "  -1.03567831e-01 -6.39848635e-02 -8.01977934e-04 -1.85797568e-02\n",
      "  -1.14910677e-02  4.10608761e-02  9.33007058e-03 -6.32518297e-03\n",
      "   3.46878283e-02 -6.61663786e-02 -3.84401553e-03  8.73872917e-03\n",
      "   8.80816579e-02  7.76215568e-02 -2.91920751e-02  8.15580785e-02\n",
      "   3.55008505e-02  3.10492925e-02 -4.45909845e-03  8.02676082e-02\n",
      "  -1.24499546e-02  1.06032798e-02  6.93551600e-02 -5.33105396e-02\n",
      "  -2.35140324e-02  1.33174025e-02 -7.67698558e-03  3.32195731e-03\n",
      "   3.02499980e-02 -3.32984366e-02  8.44772682e-02  2.32913364e-02\n",
      "   7.94830695e-02 -6.08169474e-02 -3.99631970e-02  1.75625887e-02\n",
      "   1.37093052e-01 -2.14149244e-02  6.23604804e-02 -4.33418527e-02\n",
      "   1.25400469e-01 -2.90089864e-02 -3.52325626e-02  7.52617642e-02\n",
      "   1.18724415e-02  8.23247209e-02 -1.51907820e-02  5.82811004e-03\n",
      "  -2.88471989e-02  2.04949453e-02 -1.49239048e-01 -3.95601355e-02\n",
      "   1.67078860e-02 -4.44729067e-03 -2.13512834e-02  1.34153469e-02\n",
      "  -4.63214256e-02 -7.49955699e-03 -7.52882436e-02 -1.31220132e-01\n",
      "   1.65015489e-01 -9.30287763e-02  7.05149164e-03 -4.97146845e-02\n",
      "   3.96973034e-03  1.44314095e-02  8.90425816e-02 -4.38117981e-02\n",
      "  -6.85445517e-02 -1.90478545e-02 -6.36816025e-02 -4.07023691e-02\n",
      "   6.31273091e-02  6.78196102e-02  1.84689499e-02  2.43970584e-02\n",
      "   2.67180204e-02  4.51094881e-02  1.07540833e-02  2.62367614e-02\n",
      "  -1.09662883e-01 -3.57086509e-02  7.43294284e-02  1.69675669e-03\n",
      "  -9.24099386e-02 -1.23565294e-01 -6.16702400e-02  5.88159598e-02\n",
      "  -3.64866927e-02  8.88293162e-02  1.04467444e-01 -6.52237833e-02\n",
      "   1.38118863e-01  2.11383030e-02  9.56853330e-02  3.46836671e-02\n",
      "  -5.88270053e-02  8.32267404e-02 -9.49602723e-02  3.71114127e-02\n",
      "   2.97985002e-02 -1.11650169e-01 -6.24489263e-02 -1.39175924e-02\n",
      "   2.29521305e-03  3.80262844e-02 -5.83253754e-03  1.36442393e-01\n",
      "   2.24896017e-02  3.16885561e-02  5.81982769e-02 -2.41253637e-02\n",
      "   2.78215110e-02  3.40348892e-02 -9.42610130e-02 -6.76867366e-02\n",
      "  -4.47969176e-02  2.69597881e-02 -4.51286100e-02  1.52183017e-02\n",
      "  -2.77415495e-02  7.01747537e-02 -5.38194664e-02 -1.16572022e-01\n",
      "   1.50123872e-02 -2.53710542e-02 -4.01730947e-02 -1.07358560e-01\n",
      "   3.26252589e-03 -4.59762886e-02  7.30254874e-02 -2.55695451e-03\n",
      "   6.08895458e-02 -1.06824838e-01  3.86044085e-02  7.21649127e-03\n",
      "   2.76189391e-02  3.87012288e-02  4.11925055e-02 -5.88066056e-02]]\n"
     ]
    }
   ],
   "source": [
    "from utils.data import convert_example_test\n",
    "\n",
    "# 加载预训练好的无监督语义索引模型 SimCSE\n",
    "params_path='./pretrained/model_20000/model_state.pdparams'\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "# 定义两条文本数据\n",
    "test_data = ['国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据', '语义检索相关的论文']\n",
    "# 给convert_example_test赋予默认值\n",
    "test_func = partial(\n",
    "        convert_example_test,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "# pad对齐操作\n",
    "test_batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # text_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # text_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# conver_example function's input must be dict\n",
    "corpus_ds = MapDataset(test_data)\n",
    "# 构造Dataloader\n",
    "corpus_data_loader = create_dataloader(\n",
    "        corpus_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=test_batchify_fn,\n",
    "        trans_fn=test_func)\n",
    "\n",
    "all_embeddings = []\n",
    "# 切换成eval模式，固定住 dropout\n",
    "model.eval()\n",
    "# 预测的时候不保存梯度\n",
    "with paddle.no_grad():\n",
    "    for batch_data in corpus_data_loader:\n",
    "        input_ids, token_type_ids = batch_data\n",
    "        input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "        token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "        # 抽取向量\n",
    "        text_embeddings = model.get_pooled_embedding(input_ids, token_type_ids)\n",
    "        all_embeddings.append(text_embeddings)\n",
    "\n",
    "text_embedding=all_embeddings[0]\n",
    "print(text_embedding.shape)\n",
    "print(text_embedding.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从输出结果可以看出，两条文本被抽取成了2条256维度的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有监督语义索引\n",
    "#### 数据准备\n",
    "\n",
    "使用文献的的query, title, keywords，构造带正标签的数据集，不包含负标签样本\n",
    "\n",
    "```\n",
    "宁夏社区图书馆服务体系布局现状分析\t       宁夏社区图书馆服务体系布局现状分析社区图书馆,社区图书馆服务,社区图书馆服务体系\n",
    "人口老龄化对京津冀经济\t                 京津冀人口老龄化对区域经济增长的影响京津冀,人口老龄化,区域经济增长,固定效应模型\n",
    "英语广告中的模糊语\t                  模糊语在英语广告中的应用及其功能模糊语,英语广告,表现形式,语用功能\n",
    "甘氨酸二肽的合成\t                      甘氨酸二肽合成中缩合剂的选择甘氨酸,缩合剂,二肽\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:24.795033Z",
     "iopub.status.busy": "2022-09-09T12:37:24.794333Z",
     "iopub.status.idle": "2022-09-09T12:37:24.814283Z",
     "shell.execute_reply": "2022-09-09T12:37:24.813394Z",
     "shell.execute_reply.started": "2022-09-09T12:37:24.795002Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:37:21.250246800Z",
     "start_time": "2024-06-01T07:37:21.222574900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_a': '从《唐律疏义》看唐代封爵贵族的法律特权', 'text_b': '从《唐律疏义》看唐代封爵贵族的法律特权《唐律疏义》,封爵贵族,法律特权'}\n",
      "{'text_a': '宁夏社区图书馆服务体系布局现状分析', 'text_b': '宁夏社区图书馆服务体系布局现状分析社区图书馆,社区图书馆服务,社区图书馆服务体系'}\n",
      "{'text_a': '人口老龄化对京津冀经济', 'text_b': '京津冀人口老龄化对区域经济增长的影响京津冀,人口老龄化,区域经济增长,固定效应模型'}\n"
     ]
    }
   ],
   "source": [
    "def read_text_pair(data_path):\n",
    "    \"\"\"Reads data.\"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = line.rstrip().split(\"\\t\")\n",
    "            if len(data) != 2:\n",
    "                continue\n",
    "            # 可以看到有监督数据使用query title pair的\n",
    "            # 所以text_a和text_b不一样\n",
    "            yield {'text_a': data[0], 'text_b': data[1]}\n",
    "\n",
    "train_set_file='./train.csv'\n",
    "train_ds = load_dataset(\n",
    "        read_text_pair, data_path=train_set_file, lazy=False)\n",
    "# 打印3条文本\n",
    "for i in range(3):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到有监督的In-batch Negatives的训练输入的文本text_a,text_b是不一样的，表示的是text_a和text_b是相似的文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:24.816036Z",
     "iopub.status.busy": "2022-09-09T12:37:24.815551Z",
     "iopub.status.idle": "2022-09-09T12:37:24.826406Z",
     "shell.execute_reply": "2022-09-09T12:37:24.825550Z",
     "shell.execute_reply.started": "2022-09-09T12:37:24.816009Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:37:23.711168900Z",
     "start_time": "2024-06-01T07:37:23.684169200Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.base_model import SemanticIndexBase\n",
    "\n",
    "class SemanticIndexBatchNeg(SemanticIndexBase):\n",
    "    def __init__(self,\n",
    "                 pretrained_model,\n",
    "                 dropout=None,\n",
    "                 margin=0.3,\n",
    "                 scale=30,\n",
    "                 output_emb_size=None):\n",
    "        super().__init__(pretrained_model, dropout, output_emb_size)\n",
    "\n",
    "        self.margin = margin\n",
    "        # Used scaling cosine similarity to ease converge\n",
    "        self.sacle = scale\n",
    "\n",
    "    def forward(self,\n",
    "                query_input_ids,\n",
    "                title_input_ids,\n",
    "                query_token_type_ids=None,\n",
    "                query_position_ids=None,\n",
    "                query_attention_mask=None,\n",
    "                title_token_type_ids=None,\n",
    "                title_position_ids=None,\n",
    "                title_attention_mask=None):\n",
    "\n",
    "        query_cls_embedding = self.get_pooled_embedding(\n",
    "            query_input_ids, query_token_type_ids, query_position_ids,\n",
    "            query_attention_mask)\n",
    "\n",
    "        title_cls_embedding = self.get_pooled_embedding(\n",
    "            title_input_ids, title_token_type_ids, title_position_ids,\n",
    "            title_attention_mask)\n",
    "\n",
    "        cosine_sim = paddle.matmul(\n",
    "            query_cls_embedding, title_cls_embedding, transpose_y=True)\n",
    "\n",
    "        # substract margin from all positive samples cosine_sim()\n",
    "        margin_diag = paddle.full(\n",
    "            shape=[query_cls_embedding.shape[0]],\n",
    "            fill_value=self.margin,\n",
    "            dtype=paddle.get_default_dtype())\n",
    "\n",
    "        cosine_sim = cosine_sim - paddle.diag(margin_diag)\n",
    "\n",
    "        # scale cosine to ease training converge\n",
    "        cosine_sim *= self.sacle\n",
    "\n",
    "        labels = paddle.arange(0, query_cls_embedding.shape[0], dtype='int64')\n",
    "        labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "\n",
    "        loss = F.cross_entropy(input=cosine_sim, label=labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从模型层面来讲SimCSE的结构和Inbatch-Negatives的网络结构没有区别，唯一最大的区别是训练过程使用了有监督的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练配置\n",
    "\n",
    "定义模型训练的超参，优化器等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:24.828006Z",
     "iopub.status.busy": "2022-09-09T12:37:24.827579Z",
     "iopub.status.idle": "2022-09-09T12:37:24.832232Z",
     "shell.execute_reply": "2022-09-09T12:37:24.831433Z",
     "shell.execute_reply.started": "2022-09-09T12:37:24.827980Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:37:38.043354900Z",
     "start_time": "2024-06-01T07:37:38.019153700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# 最大序列长度\n",
    "max_seq_length=64\n",
    "epochs=1\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0\n",
    "weight_decay=0.0\n",
    "save_steps=10\n",
    "batch_size=64\n",
    "output_emb_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:24.833720Z",
     "iopub.status.busy": "2022-09-09T12:37:24.833475Z",
     "iopub.status.idle": "2022-09-09T12:37:25.987450Z",
     "shell.execute_reply": "2022-09-09T12:37:25.986443Z",
     "shell.execute_reply.started": "2022-09-09T12:37:24.833699Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:37:50.590382300Z",
     "start_time": "2024-06-01T07:37:42.301234400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-01 15:37:42,301] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:37:42,302] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:37:42,510] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:37:50,520] [ WARNING]\u001B[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieModel: ['ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:37:50,520] [ WARNING]\u001B[0m - Some weights of ErnieModel were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['ernie.pooler.dense.bias', 'ernie.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:37:50,543] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\ernie_3.0_medium_zh_vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:37:50,562] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:37:50,563] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\special_tokens_map.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-3.0-medium-zh')\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length) \n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # query_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # query_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # title_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # tilte_segment\n",
    "    ): [data for data in fn(samples)]  \n",
    "\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "# Inbatch-Negatives\n",
    "model = SemanticIndexBatchNeg(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion) \n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练\n",
    "\n",
    "模型训练过程如下：\n",
    "\n",
    "1.从dataloader中取出小批量数据\n",
    "\n",
    "2.输入到模型中做前向\n",
    "\n",
    "3.求损失函数\n",
    "\n",
    "3.反向传播更新梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:25.989514Z",
     "iopub.status.busy": "2022-09-09T12:37:25.988841Z",
     "iopub.status.idle": "2022-09-09T12:37:42.898182Z",
     "shell.execute_reply": "2022-09-09T12:37:42.897036Z",
     "shell.execute_reply.started": "2022-09-09T12:37:25.989483Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def do_train(model,train_data_loader):\n",
    "    \n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            query_input_ids, query_token_type_ids, title_input_ids, title_token_type_ids = batch\n",
    "\n",
    "            loss = model(\n",
    "                query_input_ids=query_input_ids,\n",
    "                title_input_ids=title_input_ids,\n",
    "                query_token_type_ids=query_token_type_ids,\n",
    "                title_token_type_ids=title_token_type_ids)\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step % 5 == 0:\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            if global_step % save_steps == 0:\n",
    "                save_path = os.path.join(save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_path)\n",
    "\n",
    "do_train(model,train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 模型预测\n",
    "\n",
    "模型预测部分加载训练好的模型，然后输入两条示例数据进行预测抽取向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:42.900407Z",
     "iopub.status.busy": "2022-09-09T12:37:42.899777Z",
     "iopub.status.idle": "2022-09-09T12:37:47.290883Z",
     "shell.execute_reply": "2022-09-09T12:37:47.289804Z",
     "shell.execute_reply.started": "2022-09-09T12:37:42.900375Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  inbatch_model.zip\r\n",
      "  inflating: pretrained/model_40/model_state.pdparams  \r\n",
      "  inflating: pretrained/model_40/vocab.txt  \r\n",
      "  inflating: pretrained/model_40/tokenizer_config.json  \r\n"
     ]
    }
   ],
   "source": [
    "# !wget https://bj.bcebos.com/v1/paddlenlp/models/inbatch_model.zip \n",
    "\n",
    "if(not os.path.exists('inbatch_model.zip')):\n",
    "    get_path_from_url('https://bj.bcebos.com/v1/paddlenlp/models/inbatch_model.zip',root_dir='.')\n",
    "\n",
    "# !unzip -o inbatch_model.zip -d pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:47.293110Z",
     "iopub.status.busy": "2022-09-09T12:37:47.292441Z",
     "iopub.status.idle": "2022-09-09T12:37:51.507941Z",
     "shell.execute_reply": "2022-09-09T12:37:51.507129Z",
     "shell.execute_reply.started": "2022-09-09T12:37:47.293075Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:38:19.656885300Z",
     "start_time": "2024-06-01T07:38:09.168334300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-01 15:38:09,170] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-1.0\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:38:09,170] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-1.0\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:38:09,545] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:38:18,747] [ WARNING]\u001B[0m - Some weights of the model checkpoint at ernie-1.0 were not used when initializing ErnieModel: ['cls.predictions.layer_norm.weight', 'cls.predictions.transform.weight', 'cls.predictions.decoder_bias', 'cls.predictions.layer_norm.bias', 'cls.predictions.transform.bias']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:38:18,748] [    INFO]\u001B[0m - All the weights of ErnieModel were initialized from the model checkpoint at ernie-1.0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ErnieModel for predictions without further training.\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:38:18,778] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-1.0\\vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:38:18,803] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-1.0\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:38:18,804] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-1.0\\special_tokens_map.json\u001B[0m\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1865: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\n",
      "You can set full_graph=True, then you can assign input spec.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 256]\n",
      "[[ 0.07830597 -0.1403687   0.03433796 -0.14967981 -0.03386056  0.06630653\n",
      "   0.01357932  0.03531206  0.02411087  0.0200086   0.0572399  -0.08119465\n",
      "   0.06286903  0.06509128  0.0719341   0.06378152  0.00466652  0.04162082\n",
      "   0.09570316 -0.04379361  0.02414248  0.04090641  0.00377305  0.02440115\n",
      "  -0.14362058  0.01603018  0.00888093  0.01143386 -0.05140319  0.05263366\n",
      "   0.05756421 -0.10277359 -0.02346238  0.01396164  0.01603572  0.05159243\n",
      "   0.02901114  0.07017182  0.01261908  0.01556086  0.01930514 -0.01243163\n",
      "  -0.00569786 -0.18707049 -0.03321618  0.00187249  0.0162295   0.07697202\n",
      "   0.04228468  0.02567651  0.06987978 -0.03897954 -0.03276315  0.00794893\n",
      "   0.00679751  0.06019309 -0.07035226  0.00915677 -0.04332462  0.03413434\n",
      "   0.00501309 -0.07866681 -0.11235965 -0.03109914 -0.02952522 -0.08572644\n",
      "   0.01957936  0.0331405   0.06148316  0.14422092 -0.03898615  0.04563016\n",
      "  -0.08464758 -0.07827485 -0.03478685  0.00342681 -0.05538592 -0.03798989\n",
      "  -0.02372422  0.06929096 -0.04177903 -0.03609531 -0.00946311 -0.05902933\n",
      "   0.05852191  0.00282573 -0.12277576  0.01283278 -0.0240921   0.02010887\n",
      "  -0.0371126   0.00623426 -0.13293044  0.02152391 -0.07789825  0.09509639\n",
      "  -0.06737805 -0.04944953 -0.09639065  0.00861308 -0.05997343 -0.06521506\n",
      "  -0.00191429 -0.01571749  0.00239078  0.07655739 -0.04555859  0.03111982\n",
      "  -0.02936373 -0.03534597 -0.01236845 -0.00591724  0.01960543 -0.02594505\n",
      "   0.13196976 -0.02176675  0.03869962 -0.05644072 -0.06269866  0.00492577\n",
      "  -0.02510541  0.02516208 -0.02516598 -0.04163452  0.14240724  0.13721557\n",
      "   0.05525026  0.01423837  0.03205589  0.07035212  0.03287431  0.0117072\n",
      "  -0.0246513   0.00981506  0.02906037 -0.01547883 -0.08650852  0.09749672\n",
      "  -0.01942934 -0.01907328  0.03711834 -0.05219145  0.03817443 -0.12468965\n",
      "   0.08577224  0.06136187 -0.04887719 -0.01135095 -0.00135078 -0.01245416\n",
      "   0.03724625  0.00724624  0.00682228  0.03375356  0.05275378  0.0064358\n",
      "  -0.03026574  0.00245504  0.01779652  0.06211034  0.04125038 -0.01350957\n",
      "   0.03823708  0.0852924  -0.00881568 -0.04071283 -0.04333315 -0.04984052\n",
      "   0.01493568  0.13698883 -0.07577145  0.20749275 -0.02095129  0.02333715\n",
      "   0.15887691  0.08057289  0.10368982  0.01645215 -0.09263836  0.01238905\n",
      "   0.09738436  0.02532267 -0.06194213  0.00996006 -0.05673226 -0.06030709\n",
      "   0.07381689 -0.01247     0.16298793 -0.13664483  0.02330154  0.00774107\n",
      "   0.03312164 -0.04812352  0.02979483 -0.05061531  0.00878496 -0.01838188\n",
      "   0.05839411  0.07105394 -0.01845739  0.0206893  -0.0326968   0.01358831\n",
      "  -0.02430177  0.03913274  0.04018158 -0.07088519 -0.05662473  0.01517865\n",
      "   0.03534709  0.02760071  0.06941848  0.09429919  0.02529993  0.07677656\n",
      "   0.09641941 -0.02235315  0.06314821  0.00306688  0.06645656 -0.02354021\n",
      "   0.04892131 -0.10510913 -0.15044977  0.06165893  0.12337719  0.04014409\n",
      "  -0.06808583  0.16420086 -0.12636574 -0.03644963  0.02419663  0.06969012\n",
      "  -0.06612243 -0.01198474  0.03356671  0.10529497  0.04744643 -0.0052814\n",
      "  -0.02554769  0.07250842  0.08915228  0.14854938  0.03934029 -0.00619807\n",
      "   0.04489027 -0.04215305  0.0270334   0.03504264 -0.04022553  0.00824707\n",
      "   0.03238837  0.01795189 -0.02563948 -0.05532646]]\n"
     ]
    }
   ],
   "source": [
    "max_seq_length=64\n",
    "output_emb_size=256\n",
    "batch_size=1\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-1.0')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-1.0')\n",
    "model = SemanticIndexBatchNeg(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "params_path='./pretrained/model_40/model_state.pdparams'\n",
    "test_data = [\"国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据\"]\n",
    "# 加载模型\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "test_func = partial(\n",
    "        convert_example_test,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "test_batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # text_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # text_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# conver_example function's input must be dict\n",
    "corpus_ds = MapDataset(test_data)\n",
    "\n",
    "corpus_data_loader = create_dataloader(\n",
    "        corpus_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=test_batchify_fn,\n",
    "        trans_fn=test_func)\n",
    "\n",
    "all_embeddings = []\n",
    "model.eval()\n",
    "with paddle.no_grad():\n",
    "    for batch_data in corpus_data_loader:\n",
    "        input_ids, token_type_ids = batch_data\n",
    "        input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "        token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "        text_embeddings = model.get_pooled_embedding(input_ids, token_type_ids)\n",
    "        all_embeddings.append(text_embeddings)\n",
    "\n",
    "text_embedding=all_embeddings[0]\n",
    "print(text_embedding.shape)\n",
    "print(text_embedding.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型部署\n",
    "\n",
    "模型部署首先需要把模型转换成静态图模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:37:51.509661Z",
     "iopub.status.busy": "2022-09-09T12:37:51.509057Z",
     "iopub.status.idle": "2022-09-09T12:38:08.722945Z",
     "shell.execute_reply": "2022-09-09T12:38:08.721619Z",
     "shell.execute_reply.started": "2022-09-09T12:37:51.509620Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:39:22.402620800Z",
     "start_time": "2024-06-01T07:39:10.624070500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/recall\\inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\base\\framework.py:3044: UserWarning: The Attr(force_cpu) of Op(fill_constant) will be deprecated in the future, please use 'device_guard' instead. 'device_guard' has higher priority when they are used at the same time.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_path='./output/recall'\n",
    "model.eval()\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "print(save_path)\n",
    "paddle.jit.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:08.725361Z",
     "iopub.status.busy": "2022-09-09T12:38:08.724806Z",
     "iopub.status.idle": "2022-09-09T12:38:08.795842Z",
     "shell.execute_reply": "2022-09-09T12:38:08.794806Z",
     "shell.execute_reply.started": "2022-09-09T12:38:08.725331Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:39:43.678609500Z",
     "start_time": "2024-06-01T07:39:43.655195800Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.data import convert_example_recall_infer\n",
    "from scipy.special import softmax\n",
    "from scipy import spatial\n",
    "\n",
    "class RecallPredictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/output/recall/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/output/recall/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "\n",
    "\n",
    "    def extract_embedding(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        Predicts the data labels.\n",
    "        Args:\n",
    "            data (obj:`List(str)`): The batch data whose each element is a raw text.\n",
    "            tokenizer(obj:`PretrainedTokenizer`): This tokenizer inherits from :class:`~paddlenlp.transformers.PretrainedTokenizer`\n",
    "                which contains most of the methods. Users should refer to the superclass for more information regarding methods.\n",
    "        Returns:\n",
    "            results(obj:`dict`): All the feature vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_recall_infer(text, tokenizer)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        logits = self.output_handle.copy_to_cpu()\n",
    "        return logits\n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        Predicts the data labels.\n",
    "        Args:\n",
    "            data (obj:`List(str)`): The batch data whose each element is a raw text.\n",
    "            tokenizer(obj:`PretrainedTokenizer`): This tokenizer inherits from :class:`~paddlenlp.transformers.PretrainedTokenizer`\n",
    "                which contains most of the methods. Users should refer to the superclass for more information regarding methods.\n",
    "        Returns:\n",
    "            results(obj:`dict`): All the predictions probs.\n",
    "        \"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for idx, text in enumerate(data):\n",
    "            input_ids, segment_ids = convert_example_recall_infer({idx: text[0]}, tokenizer)\n",
    "            title_ids, title_segment_ids = convert_example_recall_infer({\n",
    "                idx: text[1]\n",
    "            }, tokenizer)\n",
    "            examples.append(\n",
    "                (input_ids, segment_ids, title_ids, title_segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        query_ids, query_segment_ids, title_ids, title_segment_ids = batchify_fn(\n",
    "            examples)\n",
    "        self.input_handles[0].copy_from_cpu(query_ids)\n",
    "        self.input_handles[1].copy_from_cpu(query_segment_ids)\n",
    "        self.predictor.run()\n",
    "        query_logits = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        self.input_handles[0].copy_from_cpu(title_ids)\n",
    "        self.input_handles[1].copy_from_cpu(title_segment_ids)\n",
    "        self.predictor.run()\n",
    "        title_logits = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        result = [\n",
    "            float(1 - spatial.distance.cosine(arr1, arr2))\n",
    "            for arr1, arr2 in zip(query_logits, title_logits)\n",
    "        ]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:08.797820Z",
     "iopub.status.busy": "2022-09-09T12:38:08.797126Z",
     "iopub.status.idle": "2022-09-09T12:38:10.973427Z",
     "shell.execute_reply": "2022-09-09T12:38:10.972408Z",
     "shell.execute_reply.started": "2022-09-09T12:38:08.797792Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:39:49.544109800Z",
     "start_time": "2024-06-01T07:39:47.530223100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取向量\n",
      "(1, 256)\n",
      "[[ 0.07830597 -0.14036867  0.03433809 -0.14967988 -0.03386061  0.06630668\n",
      "   0.01357943  0.03531198  0.0241108   0.02000859  0.05723994 -0.08119434\n",
      "   0.06286899  0.06509119  0.07193426  0.0637813   0.00466663  0.0416208\n",
      "   0.09570334 -0.0437936   0.02414249  0.04090639  0.00377312  0.02440133\n",
      "  -0.14362063  0.0160301   0.00888102  0.01143374 -0.05140326  0.05263374\n",
      "   0.05756426 -0.10277364 -0.02346236  0.0139618   0.01603572  0.05159238\n",
      "   0.0290112   0.0701718   0.01261923  0.01556097  0.01930504 -0.01243166\n",
      "  -0.00569788 -0.18707052 -0.03321596  0.00187244  0.01622939  0.07697207\n",
      "   0.04228462  0.02567671  0.06987959 -0.03897937 -0.0327629   0.00794878\n",
      "   0.00679753  0.06019303 -0.07035235  0.00915689 -0.04332461  0.0341342\n",
      "   0.00501306 -0.07866668 -0.1123596  -0.03109922 -0.02952531 -0.08572659\n",
      "   0.01957938  0.03314063  0.06148323  0.14422084 -0.03898621  0.04563032\n",
      "  -0.08464757 -0.07827486 -0.03478681  0.00342693 -0.05538582 -0.03798985\n",
      "  -0.02372419  0.06929099 -0.04177894 -0.03609536 -0.00946312 -0.05902946\n",
      "   0.0585218   0.00282569 -0.12277588  0.01283277 -0.02409217  0.02010901\n",
      "  -0.03711267  0.00623415 -0.13293031  0.0215241  -0.07789817  0.09509647\n",
      "  -0.06737803 -0.04944959 -0.09639078  0.00861305 -0.0599734  -0.06521514\n",
      "  -0.00191428 -0.01571743  0.00239078  0.07655738 -0.04555842  0.03111979\n",
      "  -0.02936376 -0.03534608 -0.01236858 -0.00591726  0.01960548 -0.02594506\n",
      "   0.1319698  -0.02176675  0.03869966 -0.05644078 -0.06269877  0.00492572\n",
      "  -0.02510531  0.02516213 -0.02516624 -0.04163454  0.14240737  0.1372155\n",
      "   0.05525025  0.01423826  0.03205597  0.07035203  0.03287417  0.01170729\n",
      "  -0.02465122  0.00981518  0.02906048 -0.01547881 -0.08650855  0.09749658\n",
      "  -0.01942945 -0.01907334  0.03711841 -0.0521915   0.03817443 -0.12468958\n",
      "   0.08577211  0.06136182 -0.04887714 -0.01135101 -0.00135071 -0.01245408\n",
      "   0.03724624  0.0072462   0.00682227  0.0337535   0.05275379  0.00643588\n",
      "  -0.03026577  0.00245526  0.01779659  0.06211039  0.04125031 -0.01350941\n",
      "   0.03823714  0.08529224 -0.00881561 -0.04071286 -0.04333323 -0.04984051\n",
      "   0.01493572  0.13698876 -0.07577167  0.20749256 -0.02095118  0.02333715\n",
      "   0.15887696  0.08057275  0.10368978  0.01645213 -0.09263828  0.01238918\n",
      "   0.09738464  0.02532281 -0.06194207  0.00996008 -0.0567322  -0.06030712\n",
      "   0.07381701 -0.01246994  0.16298799 -0.13664478  0.02330152  0.00774124\n",
      "   0.03312144 -0.0481235   0.02979493 -0.05061518  0.00878505 -0.01838184\n",
      "   0.05839417  0.0710539  -0.01845726  0.0206893  -0.03269668  0.01358839\n",
      "  -0.02430189  0.03913274  0.04018154 -0.07088515 -0.05662466  0.0151788\n",
      "   0.0353471   0.02760072  0.06941822  0.0942991   0.02530005  0.07677645\n",
      "   0.09641939 -0.02235323  0.0631481   0.00306697  0.0664564  -0.02354034\n",
      "   0.04892113 -0.10510904 -0.15044984  0.06165886  0.12337732  0.04014383\n",
      "  -0.06808592  0.1642007  -0.12636589 -0.03644963  0.02419669  0.06969011\n",
      "  -0.06612237 -0.01198481  0.03356663  0.10529493  0.04744649 -0.00528135\n",
      "  -0.02554768  0.07250843  0.0891524   0.1485495   0.03934004 -0.00619812\n",
      "   0.04489032 -0.04215311  0.02703354  0.03504271 -0.04022557  0.00824697\n",
      "   0.03238827  0.01795203 -0.02563938 -0.05532642]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir = './output/recall'\n",
    "# device='gpu'\n",
    "device='cpu'\n",
    "max_seq_length=64\n",
    "use_tensorrt = False\n",
    "batch_size =32 \n",
    "precision = 'fp32'\n",
    "cpu_threads = 1\n",
    "enable_mkldnn =False\n",
    "predictor = RecallPredictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "\n",
    "\n",
    "id2corpus = {0: '国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据'}\n",
    "corpus_list = [{idx: text} for idx, text in id2corpus.items()]\n",
    "res = predictor.extract_embedding(corpus_list, tokenizer)\n",
    "print('抽取向量')\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:10.975406Z",
     "iopub.status.busy": "2022-09-09T12:38:10.974745Z",
     "iopub.status.idle": "2022-09-09T12:38:11.761057Z",
     "shell.execute_reply": "2022-09-09T12:38:11.760214Z",
     "shell.execute_reply.started": "2022-09-09T12:38:10.975378Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:39:53.832222100Z",
     "start_time": "2024-06-01T07:39:53.551599100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算相似度\n",
      "[0.9592697000068264, 0.047252719767472806]\n"
     ]
    }
   ],
   "source": [
    "corpus_list = [['中西方语言与文化的差异', '中西方文化差异以及语言体现中西方文化,差异,语言体现'],\n",
    "                   ['中西方语言与文化的差异', '飞桨致力于让深度学习技术的创新与应用更简单']]\n",
    "res = predictor.predict(corpus_list, tokenizer)\n",
    "print('计算相似度')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导出静态图接下来就是部署了，目前部署支持C++和Pipeline两种方式，由于aistudio不支持部署环境，需要部署的话可以参考链接:[https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search/recall/in_batch_negative/deploy](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search/recall/in_batch_negative/deploy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 基于Milvus的效果展示\n",
    "\n",
    "在实际上线中，我们需要使用向量检索引擎，由于aistudio不支持搭建Milvus,有条件的同学可以本地搭建一个，使用Docker安装。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 基于Milvus搭建召回服务\n",
    "\n",
    "我们使用[Milvus](https://milvus.io/)开源工具进行召回，milvus的搭建教程请参考官方教程  [milvus官方安装教程](https://milvus.io/cn/docs/v1.1.1/milvus_docker-cpu.md)本案例使用的是milvus的1.1.1版本，搭建完以后启动milvus\n",
    "\n",
    "\n",
    "```\n",
    "cd [Milvus root path]/core/milvus\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:[Milvus root path]/core/milvus/lib\n",
    "cd scripts\n",
    "./start_server.sh\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 基于Milvus的召回效果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "输入的样本为：\n",
    "\n",
    "```\n",
    "国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据\n",
    "```\n",
    "\n",
    "下面分别是抽取的向量和召回的结果：\n",
    "\n",
    "```\n",
    "[1, 256]\n",
    "[[ 0.06374735 -0.08051944  0.05118101 -0.05855767 -0.06969483  0.05318566\n",
    "   0.079629    0.02667932 -0.04501902 -0.01187392  0.09590752 -0.05831281\n",
    "   ....\n",
    "5677638 国有股权参股对家族企业创新投入的影响混合所有制改革,国有股权,家族企业,创新投入 0.5417419672012329\n",
    "1321645 高管政治联系对民营企业创新绩效的影响——董事会治理行为的非线性中介效应高管政治联系,创新绩效,民营上市公司,董事会治理行为,中介效应 0.5445536375045776\n",
    "1340319 国有控股上市公司资产并购重组风险探讨国有控股上市公司,并购重组,防范对策 0.5515031218528748\n",
    "....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述流程就是召回的全流程，如果对精度要求不高或者数据量不高，可以完全使用召回模型得到的结果。如果数据量比较大，或者有多路召回的结果，则需要下面的排序方案，排序的作用就是对召回的结果进行重排，使得结果更加精确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:11.762713Z",
     "iopub.status.busy": "2022-09-09T12:38:11.762263Z",
     "iopub.status.idle": "2022-09-09T12:38:12.446769Z",
     "shell.execute_reply": "2022-09-09T12:38:12.445980Z",
     "shell.execute_reply.started": "2022-09-09T12:38:11.762682Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:40:08.323185300Z",
     "start_time": "2024-06-01T07:40:08.199456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 29410.80it/s]\n",
      "1000it [00:00, 33331.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印一条训练集\n",
      "{'query': '检测干眼', 'title': '诊断干眼的非侵入性新检测技术及应用价值干眼;非侵入性;检测技术;诊断', 'neg_title': '自身免疫性干眼调节T细胞及细胞因子的表达干眼CD4+CD25+Treg细胞,Th17细胞,干燥综合征,细胞因子'}\n",
      "打印一条验证集\n",
      "{'query': '中国特色社会主义文化建设理论', 'title': '建设社会主义文化强国的理论与实践思考社会主义文化强国,社会主义现代化国家,文化建设', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建读取函数，读取原始数据\n",
    "def read(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        neg_title=row['neg_title']\n",
    "        yield {'query':query, 'title':title,'neg_title':neg_title}\n",
    "\n",
    "def read_test(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        label=row['label']\n",
    "        yield {'query':query, 'title':title,'label':label}\n",
    "\n",
    "\n",
    "test_file='./dev_ranking_demo.csv'\n",
    "train_file='./train_ranking_demo.csv'\n",
    "\n",
    "train_ds=load_dataset(read,src_path=train_file,lazy=False)\n",
    "dev_ds=load_dataset(read_test,src_path=test_file,lazy=False)\n",
    "print('打印一条训练集')\n",
    "print(train_ds[0])\n",
    "print('打印一条验证集')\n",
    "print(dev_ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9b52bdae342f4d83ba80f86833d632ada5ed12abd72f4e7e8703002368732351)\n",
    "\n",
    "排序模型是pair-wise的结构，如图所示，query和titile正样本会经过encoder得到一个输出的相似度S1，query和title负样本也会经过Encoder得到一个输出的相似度S2,然后模型根据S1和S2求Triplet损失，其中S1的相似度要大于S2。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如：对于文本：\n",
    "```\n",
    "个人所得税税务筹划      基于新个税视角下的个人所得税纳税筹划分析新个税;个人所得税;纳税筹划      个人所得税工资薪金税务筹划研究个人所得税,工资薪金,税务筹划\n",
    "```\n",
    "最终构造出来一条正样本对和一条负样本对，如下：\n",
    "\n",
    "```\n",
    "正样本对：[CLS]个人所得税税务筹划[SEP]基于新个税视角下的个人所得税纳税筹划分析新个税;个人所得税;纳税筹划[SEP]\n",
    "负样本对：[CLS]个人所得税税务筹划[SEP]个人所得税工资薪金税务筹划研究个人所得税,工资薪金,税务筹划[SEP]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:12.448490Z",
     "iopub.status.busy": "2022-09-09T12:38:12.448089Z",
     "iopub.status.idle": "2022-09-09T12:38:12.896837Z",
     "shell.execute_reply": "2022-09-09T12:38:12.895946Z",
     "shell.execute_reply.started": "2022-09-09T12:38:12.448461Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:40:23.870091300Z",
     "start_time": "2024-06-01T07:40:23.850547300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\n",
      "You can set full_graph=True, then you can assign input spec.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class PairwiseMatching(nn.Layer):\n",
    "    def __init__(self, pretrained_model, dropout=None, margin=0.1):\n",
    "        super().__init__()\n",
    "        self.ptm = pretrained_model\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "        self.margin = margin\n",
    "\n",
    "        # hidden_size -> 1, calculate similarity\n",
    "        self.similarity = nn.Linear(self.ptm.config[\"hidden_size\"], 1)\n",
    "\n",
    "    # 用于导出静态图模型来计算概率\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None):\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                        position_ids, attention_mask)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # 计算相似度\n",
    "        sim = self.similarity(cls_embedding)\n",
    "        return sim\n",
    "\n",
    "\n",
    "    def predict(self,\n",
    "                input_ids,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\n",
    "                                    attention_mask)\n",
    "\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        sim_score = self.similarity(cls_embedding)\n",
    "        sim_score = F.sigmoid(sim_score)\n",
    "        return sim_score\n",
    "\n",
    "    def forward(self,\n",
    "                pos_input_ids,\n",
    "                neg_input_ids,\n",
    "                pos_token_type_ids=None,\n",
    "                neg_token_type_ids=None,\n",
    "                pos_position_ids=None,\n",
    "                neg_position_ids=None,\n",
    "                pos_attention_mask=None,\n",
    "                neg_attention_mask=None):\n",
    "\n",
    "        _, pos_cls_embedding = self.ptm(pos_input_ids, pos_token_type_ids,\n",
    "                                        pos_position_ids, pos_attention_mask)\n",
    "\n",
    "        _, neg_cls_embedding = self.ptm(neg_input_ids, neg_token_type_ids,\n",
    "                                        neg_position_ids, neg_attention_mask)\n",
    "\n",
    "        pos_embedding = self.dropout(pos_cls_embedding)\n",
    "        neg_embedding = self.dropout(neg_cls_embedding)\n",
    "\n",
    "        pos_sim = self.similarity(pos_embedding)\n",
    "        neg_sim = self.similarity(neg_embedding)\n",
    "\n",
    "        pos_sim = F.sigmoid(pos_sim)\n",
    "        neg_sim = F.sigmoid(neg_sim)\n",
    "\n",
    "        labels = paddle.full(\n",
    "            shape=[pos_cls_embedding.shape[0]], fill_value=1.0, dtype='float32')\n",
    "\n",
    "        loss = F.margin_ranking_loss(\n",
    "            pos_sim, neg_sim, labels, margin=self.margin)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练配置\n",
    "配置模型所需要的一些超参数，实例化模型，优化器等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:12.898778Z",
     "iopub.status.busy": "2022-09-09T12:38:12.897986Z",
     "iopub.status.idle": "2022-09-09T12:38:13.670896Z",
     "shell.execute_reply": "2022-09-09T12:38:13.669934Z",
     "shell.execute_reply.started": "2022-09-09T12:38:12.898747Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:40:27.539010600Z",
     "start_time": "2024-06-01T07:40:27.506737200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "margin=0.2 # 推荐取值 0.0 ~ 0.2\n",
    "eval_step=100\n",
    "max_seq_length=128\n",
    "epochs=3\n",
    "batch_size=32\n",
    "warmup_proportion=0.0\n",
    "weight_decay=0.0\n",
    "save_step=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练模型 ERNIG-Gram\n",
    "基于 ERNIE-3.0-Medium-zh 热启训练单塔 Pair-wise 排序模型，并定义数据读取的 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:13.672735Z",
     "iopub.status.busy": "2022-09-09T12:38:13.672122Z",
     "iopub.status.idle": "2022-09-09T12:38:15.389917Z",
     "shell.execute_reply": "2022-09-09T12:38:15.389119Z",
     "shell.execute_reply.started": "2022-09-09T12:38:13.672702Z"
    },
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-01T07:40:40.269109Z",
     "start_time": "2024-06-01T07:40:32.595451800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-01 15:40:32,596] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:40:32,597] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:40:32,912] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:40:40,208] [ WARNING]\u001B[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieModel: ['ernie.encoder.layers.6.norm2.weight', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[33m[2024-06-01 15:40:40,208] [ WARNING]\u001B[0m - Some weights of ErnieModel were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['ernie.pooler.dense.bias', 'ernie.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:40:40,229] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\ernie_3.0_medium_zh_vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:40:40,245] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:40:40,246] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-3.0-medium-zh\\special_tokens_map.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "\n",
    "trans_func_train = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "trans_func_eval = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"eval\")\n",
    "\n",
    "batchify_fn_train = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pos_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pos_pair_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # neg_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64')  # neg_pair_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "batchify_fn_eval = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pair_segment\n",
    "        Stack(dtype=\"int64\")  # label\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_train,\n",
    "        trans_fn=trans_func_train)\n",
    "\n",
    "dev_data_loader = create_dataloader(\n",
    "        dev_ds,\n",
    "        mode='dev',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_eval,\n",
    "        trans_fn=trans_func_eval)\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:15.391459Z",
     "iopub.status.busy": "2022-09-09T12:38:15.391073Z",
     "iopub.status.idle": "2022-09-09T12:38:15.561093Z",
     "shell.execute_reply": "2022-09-09T12:38:15.560085Z",
     "shell.execute_reply.started": "2022-09-09T12:38:15.391431Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:40:46.650638800Z",
     "start_time": "2024-06-01T07:40:46.427672700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[32, 71], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1    , 12052, 127  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 69   , 12   , ..., 92   , 2    , 0    ],\n",
      "        [1    , 12052, 215  , ..., 0    , 0    , 0    ],\n",
      "        ...,\n",
      "        [1    , 12   , 403  , ..., 57   , 393  , 2    ],\n",
      "        [1    , 1086 , 306  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 756  , 387  , ..., 0    , 0    , 0    ]]), Tensor(shape=[32, 71], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 1, 1, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 1, 1, 1],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]), Tensor(shape=[32, 88], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1    , 12052, 127  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 69   , 12   , ..., 0    , 0    , 0    ],\n",
      "        [1    , 12052, 215  , ..., 0    , 0    , 0    ],\n",
      "        ...,\n",
      "        [1    , 12   , 403  , ..., 196  , 503  , 2    ],\n",
      "        [1    , 1086 , 306  , ..., 0    , 0    , 0    ],\n",
      "        [1    , 756  , 387  , ..., 0    , 0    , 0    ]]), Tensor(shape=[32, 88], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 1, 1, 1],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]])]\n",
      "[Tensor(shape=[32, 103], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1    , 12   , 20   , ..., 0    , 0    , 0    ],\n",
      "        [1    , 65   , 1237 , ..., 0    , 0    , 0    ],\n",
      "        [1    , 3133 , 886  , ..., 0    , 0    , 0    ],\n",
      "        ...,\n",
      "        [1    , 924  , 1458 , ..., 0    , 0    , 0    ],\n",
      "        [1    , 39643, 21   , ..., 0    , 0    , 0    ],\n",
      "        [1    , 458  , 31   , ..., 0    , 0    , 0    ]]), Tensor(shape=[32, 103], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]), Tensor(shape=[32], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1865: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 打印训练集的batch数据\n",
    "for item in train_data_loader:\n",
    "    print(item)\n",
    "    break\n",
    "\n",
    "# 打印验证集的batch数据\n",
    "for item in dev_data_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集的数据包含4个Tensor，分别表示的是query和正样本title的input_ids和token_type_ids，以及query和负样本title的input_ids和token_type_ids。\n",
    "\n",
    "验证集则不一样，包含3个Tensor，除了了query后天title拼接成的input_id和token_type_ids的形式为，还有label，表明这条query和title是否相似，1表示的是相似，0表示的是不相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "下面是模型训练过程，由于在训练的时候使用了评估，所以先构建评估函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:15.562898Z",
     "iopub.status.busy": "2022-09-09T12:38:15.562628Z",
     "iopub.status.idle": "2022-09-09T12:38:16.106922Z",
     "shell.execute_reply": "2022-09-09T12:38:16.105972Z",
     "shell.execute_reply.started": "2022-09-09T12:38:15.562873Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:40:56.416252700Z",
     "start_time": "2024-06-01T07:40:56.389645700Z"
    }
   },
   "outputs": [],
   "source": [
    "@paddle.no_grad()\n",
    "def evaluate(model, metric, data_loader, phase=\"dev\"):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        # 类别为正的概率\n",
    "        pos_probs = model.predict(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        # 类别为负的概率\n",
    "        neg_probs = 1.0 - pos_probs\n",
    "\n",
    "        preds = np.concatenate((neg_probs, pos_probs), axis=1)\n",
    "        metric.update(preds=preds, labels=labels)\n",
    "\n",
    "    print(\"eval_{} auc:{:.3}\".format(phase, metric.accumulate()))\n",
    "    metric.reset()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是排序模型的训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:16.108860Z",
     "iopub.status.busy": "2022-09-09T12:38:16.108499Z",
     "iopub.status.idle": "2022-09-09T12:38:30.162952Z",
     "shell.execute_reply": "2022-09-09T12:38:30.161966Z",
     "shell.execute_reply.started": "2022-09-09T12:38:16.108832Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T04:17:07.800919400Z",
     "start_time": "2024-05-31T04:14:19.269451800Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 58\u001B[0m\n\u001B[0;32m     55\u001B[0m                 paddle\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), save_param_path)\n\u001B[0;32m     56\u001B[0m                 tokenizer\u001B[38;5;241m.\u001B[39msave_pretrained(save_path)\n\u001B[1;32m---> 58\u001B[0m \u001B[43mdo_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdev_data_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[38], line 42\u001B[0m, in \u001B[0;36mdo_train\u001B[1;34m(model, train_data_loader, dev_data_loader)\u001B[0m\n\u001B[0;32m     40\u001B[0m     tic_train \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# 反向求梯度\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     44\u001B[0m lr_scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[0;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[1;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\base\\wrapped_decorator.py:26\u001B[0m, in \u001B[0;36mwrap_decorator.<locals>.__impl__\u001B[1;34m(func, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;129m@decorator\u001B[39m\u001B[38;5;241m.\u001B[39mdecorator\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__impl__\u001B[39m(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     25\u001B[0m     wrapped_func \u001B[38;5;241m=\u001B[39m decorator_func(func)\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\base\\framework.py:593\u001B[0m, in \u001B[0;36m_dygraph_only_.<locals>.__impl__\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__impl__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    589\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m in_dygraph_mode(), (\n\u001B[0;32m    590\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe only support \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in dynamic graph mode, please call \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaddle.disable_static()\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to enter dynamic graph mode.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    591\u001B[0m         \u001B[38;5;241m%\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m    592\u001B[0m     )\n\u001B[1;32m--> 593\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\base\\dygraph\\tensor_patch_methods.py:342\u001B[0m, in \u001B[0;36mmonkey_patch_tensor.<locals>.backward\u001B[1;34m(self, grad_tensor, retain_graph)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _grad_scalar:\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;66;03m# When using amp with Fleet DistributedStrategy, we do loss scaling implicitly.\u001B[39;00m\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m _grad_scalar\u001B[38;5;241m.\u001B[39mscale(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 342\u001B[0m \u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m in_profiler_mode():\n\u001B[0;32m    345\u001B[0m     record_event\u001B[38;5;241m.\u001B[39mend()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def do_train(model,train_data_loader,dev_data_loader):\n",
    "\n",
    "    num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "    lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "    # Generate parameter names needed to perform weight decay.\n",
    "    # All bias and LayerNorm parameters are excluded.\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n",
    "    # 使用AUC作为评估指标\n",
    "    metric = paddle.metric.Auc()\n",
    "\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            pos_input_ids, pos_token_type_ids, neg_input_ids, neg_token_type_ids = batch\n",
    "\n",
    "            loss = model(\n",
    "                pos_input_ids=pos_input_ids,\n",
    "                neg_input_ids=neg_input_ids,\n",
    "                pos_token_type_ids=pos_token_type_ids,\n",
    "                neg_token_type_ids=neg_token_type_ids)\n",
    "            # 每隔10个step打印日志\n",
    "            global_step += 1\n",
    "            if global_step % 10 == 0 :\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            # 反向求梯度\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            # 每隔eval_step进行评估\n",
    "            if global_step % eval_step == 0:\n",
    "                evaluate(model, metric, dev_data_loader, \"dev\")\n",
    "            # 每隔save_steps保存模型\n",
    "            if global_step % save_step == 0:\n",
    "                save_path = os.path.join(save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_path)\n",
    "\n",
    "do_train(model,train_data_loader,dev_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 效果评估\n",
    "\n",
    "下面是效果评估，首先下载训练好的预训练模型，然后进行解压。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:30.164587Z",
     "iopub.status.busy": "2022-09-09T12:38:30.164280Z",
     "iopub.status.idle": "2022-09-09T12:38:34.614178Z",
     "shell.execute_reply": "2022-09-09T12:38:34.613074Z",
     "shell.execute_reply.started": "2022-09-09T12:38:30.164558Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T04:19:05.046530400Z",
     "start_time": "2024-05-31T04:19:04.919007600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.exists('ernie_gram_sort.zip')):\n",
    "    get_path_from_url('https://bj.bcebos.com/v1/paddlenlp/models/ernie_gram_sort.zip',root_dir='.')\n",
    "# !unzip -o ernie_gram_sort.zip -d pretrained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载训练好的模型，进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:34.616295Z",
     "iopub.status.busy": "2022-09-09T12:38:34.615677Z",
     "iopub.status.idle": "2022-09-09T12:38:41.242282Z",
     "shell.execute_reply": "2022-09-09T12:38:41.241436Z",
     "shell.execute_reply.started": "2022-09-09T12:38:34.616262Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:45:05.549245800Z",
     "start_time": "2024-06-01T07:41:45.577985200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2024-06-01 15:41:45,580] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:45,580] [    INFO]\u001B[0m - Loading weights file model_state.pdparams from cache at C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:48,975] [    INFO]\u001B[0m - Loaded weights file from disk, setting weights to model.\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:56,887] [    INFO]\u001B[0m - All model checkpoint weights were used when initializing ErnieGramModel.\n",
      "\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:56,888] [    INFO]\u001B[0m - All the weights of ErnieGramModel were initialized from the model checkpoint at ernie-gram-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ErnieGramModel for predictions without further training.\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:56,920] [    INFO]\u001B[0m - Already cached C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\vocab.txt\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:56,946] [    INFO]\u001B[0m - tokenizer config file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2024-06-01 15:41:56,947] [    INFO]\u001B[0m - Special tokens file saved in C:\\Users\\kitx86\\.paddlenlp\\models\\ernie-gram-zh\\special_tokens_map.json\u001B[0m\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2989: UserWarning: Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mset_dict(state_dict)\n\u001B[0;32m      9\u001B[0m metric \u001B[38;5;241m=\u001B[39m paddle\u001B[38;5;241m.\u001B[39mmetric\u001B[38;5;241m.\u001B[39mAuc()\n\u001B[1;32m---> 10\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdev\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[0;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[1;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\base\\dygraph\\base.py:352\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>._decorate_function\u001B[1;34m(func, *args, **kwargs)\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;129m@decorator\u001B[39m\u001B[38;5;241m.\u001B[39mdecorator\n\u001B[0;32m    350\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decorate_function\u001B[39m(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 352\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[26], line 9\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, metric, data_loader, phase)\u001B[0m\n\u001B[0;32m      7\u001B[0m input_ids, token_type_ids, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 类别为正的概率\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m pos_probs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 类别为负的概率\u001B[39;00m\n\u001B[0;32m     11\u001B[0m neg_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m pos_probs\n",
      "Cell \u001B[1;32mIn[22], line 32\u001B[0m, in \u001B[0;36mPairwiseMatching.predict\u001B[1;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     27\u001B[0m             input_ids,\n\u001B[0;32m     28\u001B[0m             token_type_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     29\u001B[0m             position_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     30\u001B[0m             attention_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 32\u001B[0m     _, cls_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptm\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m     cls_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(cls_embedding)\n\u001B[0;32m     36\u001B[0m     sim_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msimilarity(cls_embedding)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\ernie_gram\\modeling.py:315\u001B[0m, in \u001B[0;36mErnieGramModel.forward\u001B[1;34m(self, input_ids, token_type_ids, position_ids, attention_mask, inputs_embeds, past_key_values, use_cache, output_hidden_states, output_attentions, return_dict)\u001B[0m\n\u001B[0;32m    306\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m    307\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m    308\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    311\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m    312\u001B[0m )\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder\u001B[38;5;241m.\u001B[39m_use_cache \u001B[38;5;241m=\u001B[39m use_cache  \u001B[38;5;66;03m# To be consistent with HF\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, \u001B[38;5;28mtype\u001B[39m(input_ids)):\n\u001B[0;32m    325\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py:304\u001B[0m, in \u001B[0;36m_transformer_encoder_fwd\u001B[1;34m(self, src, src_mask, cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    292\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m recompute(\n\u001B[0;32m    293\u001B[0m         mod,\n\u001B[0;32m    294\u001B[0m         output,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    301\u001B[0m         output_attentions,\n\u001B[0;32m    302\u001B[0m     )\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 304\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmod\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCache\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer_outputs, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    316\u001B[0m     output \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\model_outputs.py:98\u001B[0m, in \u001B[0;36m_transformer_encoder_layer_fwd\u001B[1;34m(self, src, src_mask, cache, output_attentions)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize_before:\n\u001B[0;32m     97\u001B[0m     src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(src)\n\u001B[1;32m---> 98\u001B[0m src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear2\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear1\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m src \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout2(src)\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize_before:\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\layers.py:1429\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1421\u001B[0m     (\u001B[38;5;129;01mnot\u001B[39;00m in_to_static_mode())\n\u001B[0;32m   1422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks)\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m in_profiler_mode())\n\u001B[0;32m   1427\u001B[0m ):\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_once(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1429\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dygraph_call_func(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\layer\\common.py:185\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m--> 185\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\nn\\functional\\common.py:1960\u001B[0m, in \u001B[0;36mlinear\u001B[1;34m(x, weight, bias, name)\u001B[0m\n\u001B[0;32m   1900\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1901\u001B[0m \n\u001B[0;32m   1902\u001B[0m \u001B[38;5;124;03mFully-connected linear transformation operator. For each input :math:`X` ,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1956\u001B[0m \u001B[38;5;124;03m         [-0.67769694, -0.67769694, -0.67769694, -0.67769694]])\u001B[39;00m\n\u001B[0;32m   1957\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1958\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m in_dynamic_mode():\n\u001B[0;32m   1959\u001B[0m     \u001B[38;5;66;03m# TODO(jiabin): using addmm for fast forward route\u001B[39;00m\n\u001B[1;32m-> 1960\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_C_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1962\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m in_pir_mode():\n\u001B[0;32m   1963\u001B[0m     out \u001B[38;5;241m=\u001B[39m paddle\u001B[38;5;241m.\u001B[39m_pir_ops\u001B[38;5;241m.\u001B[39mmatmul(x, weight, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieGramModel.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieGramTokenizer.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)\n",
    "init_from_ckpt='pretrained/model_30000/model_state.pdparams'\n",
    "state_dict = paddle.load(init_from_ckpt)\n",
    "model.set_dict(state_dict)\n",
    "metric = paddle.metric.Auc()\n",
    "evaluate(model, metric, dev_data_loader, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "排序模块用的指标是AUC，随机抽出一对样本，用训练得到的分类起来对两个样本进行预测，预测得到正样本概率>负样本的概率的概率。 一般AUC达到0.7以上就算是不错的，但也要根据任务场景进行分析，有的可能连0.7也达不到，但是效果也是非常不错的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:41.244052Z",
     "iopub.status.busy": "2022-09-09T12:38:41.243493Z",
     "iopub.status.idle": "2022-09-09T12:38:41.250293Z",
     "shell.execute_reply": "2022-09-09T12:38:41.249551Z",
     "shell.execute_reply.started": "2022-09-09T12:38:41.244024Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:46:08.026536200Z",
     "start_time": "2024-06-01T07:46:08.004735500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。'}\n"
     ]
    }
   ],
   "source": [
    "from utils.data import read_text_pair\n",
    "input_file='test_pairwise.csv'\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印一条数据\n",
    "print(valid_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:41.251849Z",
     "iopub.status.busy": "2022-09-09T12:38:41.251328Z",
     "iopub.status.idle": "2022-09-09T12:38:42.618747Z",
     "shell.execute_reply": "2022-09-09T12:38:42.617917Z",
     "shell.execute_reply.started": "2022-09-09T12:38:41.251822Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:46:10.472755Z",
     "start_time": "2024-06-01T07:46:10.451398800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[5, 53], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 131 , 177 , 405 , 545 , 489 , 116 , 5   , 7   , 19  , 843 , 1767,\n",
      "         113 , 10  , 68  , 73  , 859 , 712 , 12043, 2   , 0   , 0   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 1465, 68  , 73  , 367 , 591 , 86  , 12  , 20  , 68  , 73  , 51  ,\n",
      "         137 , 241 , 812 , 216 , 1043, 3093, 1140, 1465, 68  , 73  , 30  , 12  ,\n",
      "         20  , 68  , 73  , 30  , 241 , 812 , 30  , 1197, 1285, 2   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 158 , 12  , 213 , 58  , 119 , 495 , 68  , 73  , 111 , 38  , 5   ,\n",
      "         859 , 712 , 335 , 514 , 657 , 1197, 1285, 405 , 545 , 30  , 68  , 73  ,\n",
      "         30  , 119 , 495 , 68  , 73  , 111 , 38  , 30  , 461 , 534 , 58  , 220 ,\n",
      "         30  , 1197, 1285, 2   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 12  , 514 , 68  , 73  , 859 , 712 , 51  , 1197, 1285, 5   , 347 ,\n",
      "         639 , 12  , 514 , 68  , 73  , 30  , 859 , 712 , 30  , 1197, 1285, 5   ,\n",
      "         347 , 639 , 2   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ,\n",
      "         0   , 0   , 0   , 0   , 0   ],\n",
      "        [1   , 12  , 213 , 58  , 405 , 545 , 54  , 68  , 73  , 5   , 859 , 712 ,\n",
      "         2   , 1441, 1140, 68  , 73  , 54  , 405 , 545 , 489 , 116 , 68  , 73  ,\n",
      "         30  , 405 , 545 , 30  , 68  , 73  , 54  , 405 , 545 , 5   , 129 , 135 ,\n",
      "         30  , 68  , 73  , 54  , 405 , 545 , 489 , 116 , 221 , 474 , 30  , 1465,\n",
      "         68  , 73  , 276 , 430 , 2   ]]), Tensor(shape=[5, 53], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1865: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trans_func = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"predict\")\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input_ids\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment_ids\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "test_data_loader = create_dataloader(\n",
    "        valid_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "# 打印测试的样本\n",
    "for item in test_data_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:42.620491Z",
     "iopub.status.busy": "2022-09-09T12:38:42.619899Z",
     "iopub.status.idle": "2022-09-09T12:38:43.240673Z",
     "shell.execute_reply": "2022-09-09T12:38:43.239804Z",
     "shell.execute_reply.started": "2022-09-09T12:38:42.620453Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:46:16.090442800Z",
     "start_time": "2024-06-01T07:46:14.617362500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。', 'pred_prob': 0.8511221}\n",
      "{'query': '中西方语言与文化的差异', 'title': '跨文化视角下中国文化对外传播路径琐谈跨文化,中国文化,传播,翻译', 'pred_prob': 0.7862962}\n",
      "{'query': '中西方语言与文化的差异', 'title': '从中西方民族文化心理的差异看英汉翻译语言,文化,民族文化心理,思维方式,翻译', 'pred_prob': 0.91767514}\n",
      "{'query': '中西方语言与文化的差异', 'title': '中英文化差异对翻译的影响中英文化,差异,翻译的影响', 'pred_prob': 0.8601747}\n",
      "{'query': '中西方语言与文化的差异', 'title': '浅谈文化与语言习得文化,语言,文化与语言的关系,文化与语言习得意识,跨文化交际', 'pred_prob': 0.8944413}\n"
     ]
    }
   ],
   "source": [
    "def predict(model, data_loader):\n",
    "\n",
    "    batch_probs = []\n",
    "    model.eval()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids, token_type_ids = batch_data\n",
    "\n",
    "            input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "            token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "            # 输入query title pair得到预测的概率\n",
    "            batch_prob = model.predict(\n",
    "                input_ids=input_ids, token_type_ids=token_type_ids).numpy()\n",
    "\n",
    "            batch_probs.append(batch_prob)\n",
    "        if(len(batch_prob)==1):\n",
    "            batch_probs=np.array(batch_probs)\n",
    "        else:\n",
    "            batch_probs = np.concatenate(batch_probs, axis=0)\n",
    "        return batch_probs\n",
    "\n",
    "\n",
    "\n",
    "y_probs = predict(model, test_data_loader)\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印输出\n",
    "for idx, prob in enumerate(y_probs):\n",
    "    text_pair = valid_ds[idx]\n",
    "    text_pair[\"pred_prob\"] = prob[0]\n",
    "    print(text_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测部署\n",
    "\n",
    "首先把动态图模型转换成静态图模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:38:43.242401Z",
     "iopub.status.busy": "2022-09-09T12:38:43.241807Z",
     "iopub.status.idle": "2022-09-09T12:39:00.691119Z",
     "shell.execute_reply": "2022-09-09T12:39:00.689766Z",
     "shell.execute_reply.started": "2022-09-09T12:38:43.242371Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:46:55.239825500Z",
     "start_time": "2024-06-01T07:46:45.348211900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\n",
      "You can set full_graph=True, then you can assign input spec.\n",
      "\n",
      "  warnings.warn(\n",
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddle\\jit\\dy2static\\program_translator.py:712: UserWarning: full_graph=False don't support input_spec arguments. It will not produce any effect.\n",
      "You can set full_graph=True, then you can assign input spec.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_path='output/rank'\n",
    "model.eval()\n",
    "\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "paddle.jit.save(model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义Predictor用于加载静态图的模型参数进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:39:00.693299Z",
     "iopub.status.busy": "2022-09-09T12:39:00.692850Z",
     "iopub.status.idle": "2022-09-09T12:39:00.707099Z",
     "shell.execute_reply": "2022-09-09T12:39:00.705900Z",
     "shell.execute_reply.started": "2022-09-09T12:39:00.693270Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:47:57.175912100Z",
     "start_time": "2024-06-01T07:47:57.163573200Z"
    }
   },
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/output/rank/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/output/rank/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "     \n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "        \n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_ranking(\n",
    "                text,\n",
    "                tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                is_test=True)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        sim_score = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        sim_score = expit(sim_score)\n",
    "\n",
    "        return sim_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取测试集的文本，把文本利用convert_example_ranking函数转换成id向量的形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:39:00.715464Z",
     "iopub.status.busy": "2022-09-09T12:39:00.714699Z",
     "iopub.status.idle": "2022-09-09T12:39:00.723966Z",
     "shell.execute_reply": "2022-09-09T12:39:00.723172Z",
     "shell.execute_reply.started": "2022-09-09T12:39:00.715436Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:48:09.255055300Z",
     "start_time": "2024-06-01T07:48:09.236308500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。'}, {'query': '中西方语言与文化的差异', 'title': '跨文化视角下中国文化对外传播路径琐谈跨文化,中国文化,传播,翻译'}, {'query': '中西方语言与文化的差异', 'title': '从中西方民族文化心理的差异看英汉翻译语言,文化,民族文化心理,思维方式,翻译'}, {'query': '中西方语言与文化的差异', 'title': '中英文化差异对翻译的影响中英文化,差异,翻译的影响'}, {'query': '中西方语言与文化的差异', 'title': '浅谈文化与语言习得文化,语言,文化与语言的关系,文化与语言习得意识,跨文化交际'}]\n"
     ]
    }
   ],
   "source": [
    "def convert_example_ranking(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "\n",
    "    query, title = example[\"query\"], example[\"title\"]\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n",
    "\n",
    "input_file='test_pairwise.csv'\n",
    "\n",
    "test_ds = load_dataset(read_text_pair,data_path=input_file, lazy=False)\n",
    "\n",
    "data = [{'query': d['query'], 'title': d['title']} for d in test_ds]\n",
    "\n",
    "batches = [\n",
    "        data[idx:idx + batch_size]\n",
    "        for idx in range(0, len(data), batch_size)\n",
    "    ]\n",
    "print(batches[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化Predictor，然后进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-09T12:39:00.725271Z",
     "iopub.status.busy": "2022-09-09T12:39:00.725034Z",
     "iopub.status.idle": "2022-09-09T12:39:02.013373Z",
     "shell.execute_reply": "2022-09-09T12:39:02.012269Z",
     "shell.execute_reply.started": "2022-09-09T12:39:00.725249Z"
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T07:48:16.572153900Z",
     "start_time": "2024-06-01T07:48:14.769791200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {'query': '中西方语言与文化的差异', 'title': '第二语言习得的一大障碍就是文化差异。'} \t prob: [0.8511221]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '跨文化视角下中国文化对外传播路径琐谈跨文化,中国文化,传播,翻译'} \t prob: [0.78629637]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '从中西方民族文化心理的差异看英汉翻译语言,文化,民族文化心理,思维方式,翻译'} \t prob: [0.91767514]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '中英文化差异对翻译的影响中英文化,差异,翻译的影响'} \t prob: [0.86017483]\n",
      "Data: {'query': '中西方语言与文化的差异', 'title': '浅谈文化与语言习得文化,语言,文化与语言的关系,文化与语言习得意识,跨文化交际'} \t prob: [0.8944415]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\system_default\\desktop\\Github_repo_code\\RecSys\\venv\\Lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir='output/rank'\n",
    "device='gpu'\n",
    "max_seq_length=128\n",
    "batch_size=32\n",
    "# 可以安装对应的Tensorrt之后进行加速\n",
    "use_tensorrt=False\n",
    "# 精度，也可以选择fp16，精度几乎无损\n",
    "precision='fp32'\n",
    "# cpu的线程数目\n",
    "cpu_threads=10\n",
    "# 可以在CPU的情况下进行加速\n",
    "enable_mkldnn=False\n",
    "\n",
    "predictor = Predictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "results = []\n",
    "for batch_data in batches:\n",
    "    results.extend(predictor.predict(batch_data, tokenizer))\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t prob: {}'.format(text, results[idx]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
